from scipy.spatial.transform import Rotation
import numpy as np
import itertools
import einops
import torch



def rotate(vector,R, rotation_center=None, inverse=False):
    """Rotate tensor by scipy Rotation around a rotation center"""
    ret = vector.reshape(-1,3)
    if rotation_center is not None:
        ret = ret-rotation_center
    ret = torch.tensor(R.apply(ret.numpy(),inverse)).float()
    if rotation_center is not None:
        ret = ret+rotation_center
    return ret.reshape(vector.shape)

def sample_matrix(input_shape:tuple, R:Rotation, offset:torch.Tensor, w:int, slice_function:Callable, rotation_center=None):
    """Sample a sparse matrix that represents the projection of a volume onto a plane
    
    Outside the volume it is zero padded
    
    Parameters
    ----------
    R: scipy.spatial.transform.Rotation 
        Rotation that describes the orientation of the plane
    offset: torch.Tensor
        Offset of the plane in the volume
    w: int
        Factor that determines the number of pixels that are considered in the projection along the slice direction
    slice_function: Callable
        Function that describes the slice profile
    rotation_center: torch.Tensor
        Center of rotation, if None the center of the volume is used, i.e. for 4 pixels 0 1 2 3 it is between 1 and 2
        
    Returns
    -------
    torch.sparse_csr_matrix
        Sparse matrix that represents the projection of the volume onto the plane
    """
    X,Y,Z = input_shape
    pixel = torch.stack(list(torch.meshgrid(torch.arange(X), torch.arange(Y))) + [Z/2*torch.ones(X, Y)], dim=-1)
    pixel = pixel + offset
    if rotation_center is None:
        # default rotation center is the center of the volume, i.e. for 4 pixels 
        # 0 1 2 3 it is between 0 and 1
        rotation_center = torch.tensor([X/2-.5, Y/2-.5, Z/2-.5])
    pixel_rotated = rotate(pixel,R, rotation_center=rotation_center)


    # We cast a ray from the pixel perpendicular to the plane.
    # Pixels further away then w will not be considered
    # Distance between two pixels will always at least be 1
    # In all possible directions for each point aloing the line we consider the eight neighboring points
    # by adding all possible combinations of 0 and 1 to the point and flooring
    ray = rotate(torch.stack([torch.zeros(2*w), torch.zeros(2*w),torch.arange(-w,w)],dim=-1),R)
    offsets = torch.tensor(list(itertools.product([0,1], repeat=3)))
    point = (pixel_rotated[:,:,None,None,:]+ray[None,None,None,:,:] + offsets[None,None,:,None,:]).floor()
    distance = pixel_rotated[:,:,None,None,:]-point
    # Inverse rotation projects the distance back to the original coordinate system, i.e
    # Distance in z is distance along the line, i.e. the slice profile weighted direction
    # Distance in x and y is the distance of a pixel to the ray and linear interpolation is used to weight the distance
    distance_x, distance_y,distance_z = rotate(distance,R, inverse=True).unbind(-1)
    weight_xy = (1-distance_x.abs()).clamp_min(0)*(1-distance_y.abs()).clamp_min(0)
    weight_z=slice_function(distance_z)
    weight = (weight_xy*weight_z).reshape(X*Y,-1)
    
    # Remove duplicates & points outside the volume
    # This is unfortunatly much slower than using torch.sparse.coo_tensor.coalesce later on
    # ids=torch.cat([torch.arange(len(source)).unsqueeze(1).expand(source.shape[:-1]).unsqueeze(-1),source],-1).reshape(-1,4)
    # _,inverse_idx,counts=torch.unique(ids,return_counts=True,return_inverse=True,dim=0)
    # counts = counts[inverse_idx].reshape(weight.shape).float()
    # weight = weight / counts.float()
    
    source = einops.rearrange(point, 'X Y s1 s2 xyz -> (X Y) (s1 s2) xyz').int()
    # Remove points outside the volume
    mask = (source[...,0]<X) &(source[...,0]>=0) & (source[...,1]<Y) &(source[...,1]>=0) & (source[...,2]<Z) &(source[...,2]>=0)
    # We need this at the edge of the volume to approximate zero padding
    fraction_in_view=(mask*(weight>0)).sum(-1)/(weight>0).sum(-1)
    
    source_index=torch.tensor(np.ravel_multi_index(source[mask].unbind(-1), (X,Y,Z)))
    target_index=torch.repeat_interleave(torch.arange(X*Y),mask.sum(-1))

    # Count duplicates. Coalesce will sum the values of duplicate indices
    ones=torch.ones_like(source_index).float()
    ones = torch.sparse_coo_tensor(indices=torch.stack((target_index,source_index)), values=ones, size=(X*Y, X*Y*Z), dtype=torch.float32)
    ones=ones.coalesce()
    
    
    matrix = torch.sparse_coo_tensor(indices=torch.stack((target_index,source_index)), values=weight.reshape(X*Y,-1)[mask], size=(X*Y, X*Y*Z), dtype=torch.float32).coalesce()
    matrix.values()[:]/=ones.values()

    #Normalize
    norm=fraction_in_view/matrix.sum(1).to_dense()
    matrix*=norm[:,None]
    matrix=matrix.to_sparse_csr()
    
    return matrix