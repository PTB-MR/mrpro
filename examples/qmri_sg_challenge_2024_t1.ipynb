{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f82262f",
   "metadata": {},
   "source": [
    "# QMRI Challenge ISMRM 2024 - $T_1$ mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22eb134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import shutil\n",
    "import tempfile\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import zenodo_get\n",
    "from einops import rearrange\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable  # type: ignore [import-untyped]\n",
    "from mrpro.algorithms.optimizers import adam\n",
    "from mrpro.data import IData\n",
    "from mrpro.operators import MagnitudeOp\n",
    "from mrpro.operators.functionals import MSE\n",
    "from mrpro.operators.models import InversionRecovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad2180c",
   "metadata": {},
   "source": [
    "### Overview\n",
    "The dataset consists of images obtained at 10 different inversion times using a turbo spin echo sequence. Each\n",
    "inversion time is saved in a separate DICOM file. In order to obtain a $T_1$ map, we are going to:\n",
    "- download the data from Zenodo\n",
    "- read in the DICOM files (one for each inversion time) and combine them in an IData object\n",
    "- define a signal model and data loss (mean-squared error) function\n",
    "- find good starting values for each pixel\n",
    "- carry out a fit using ADAM from PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a409eb2a",
   "metadata": {},
   "source": [
    "### Get data from Zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887dafc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(tempfile.mkdtemp())\n",
    "dataset = '10868350'\n",
    "zenodo_get.zenodo_get([dataset, '-r', 5, '-o', data_folder])  # r: retries\n",
    "with zipfile.ZipFile(data_folder / Path('T1 IR.zip'), 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a23dbd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Create image data (IData) object with different inversion times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fbaeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ti_dicom_files = data_folder.glob('**/*.dcm')\n",
    "idata_multi_ti = IData.from_dicom_files(ti_dicom_files)\n",
    "\n",
    "if idata_multi_ti.header.ti is None:\n",
    "    raise ValueError('Inversion times need to be defined in the DICOM files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fb28e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at some of the images\n",
    "fig, axes = plt.subplots(1, 3, squeeze=False)\n",
    "for idx, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(torch.abs(idata_multi_ti.data[idx, 0, 0, :, :]))\n",
    "    ax.set_title(f'TI = {idata_multi_ti.header.ti[idx]:.3f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be24eb8c",
   "metadata": {},
   "source": [
    "### Signal model and loss function\n",
    "We use the model $q$\n",
    "\n",
    "$q(TI) = M_0 (1 - e^{-TI/T_1})$\n",
    "\n",
    "with the equilibrium magnetization $M_0$, the inversion time $TI$, and $T_1$. We have to keep in mind that the DICOM\n",
    "images only contain the magnitude of the signal. Therefore, we need $|q(TI)|$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6401ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MagnitudeOp() @ InversionRecovery(ti=idata_multi_ti.header.ti)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108b57f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "As a loss function for the optimizer, we calculate the mean-squared error between the image data $x$ and our signal\n",
    "model $q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69966a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = MSE(idata_multi_ti.data.abs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c2b77e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Now we can simply combine the two into a functional to solve\n",
    "\n",
    "$ \\min_{M_0, T_1} || |q(M_0, T_1, TI)| - x||_2^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01255b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "functional = mse @ model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ec6cda",
   "metadata": {},
   "source": [
    "### Starting values for the fit\n",
    "We are trying to minimize a non-linear function $q$. There is no guarantee that we reach the global minimum, but we\n",
    "can end up in a local minimum.\n",
    "\n",
    "To increase our chances of reaching the global minimum, we can ensure that our starting\n",
    "values are already close to the global minimum. We need a good starting point for each pixel.\n",
    "\n",
    "One option to get a good starting point is to calculate the signal curves for a range of $T_1$ values and then check\n",
    "for each pixel which of these signal curves fits best. This is similar to what is done for MR Fingerprinting. So we\n",
    "are going to:\n",
    "- define a list of realistic $T_1$ values (we call this a dictionary of $T_1$ values)\n",
    "- calculate the signal curves corresponding to each of these $T_1$ values\n",
    "- compare the signal curves to the signals of each voxel (we use the maximum of the dot-product as a metric of how\n",
    "well the signals fit to each other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7624e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define 100 T1 values between 0.1 and 3.0 s\n",
    "t1_dictionary = torch.linspace(0.1, 3.0, 100)\n",
    "\n",
    "# Calculate the signal corresponding to each of these T1 values. We set M0 to 1, but this is arbitrary because M0 is\n",
    "# just a scaling factor and we are going to normalize the signal curves.\n",
    "(signal_dictionary,) = model(torch.ones(1), t1_dictionary)\n",
    "signal_dictionary = signal_dictionary.to(dtype=torch.complex64)\n",
    "vector_norm = torch.linalg.vector_norm(signal_dictionary, dim=0)\n",
    "signal_dictionary /= vector_norm\n",
    "\n",
    "# Calculate the dot-product and select for each voxel the T1 values that correspond to the maximum of the dot-product\n",
    "n_y, n_x = idata_multi_ti.data.shape[-2:]\n",
    "dot_product = torch.mm(rearrange(idata_multi_ti.data, 'other 1 z y x->(z y x) other'), signal_dictionary)\n",
    "idx_best_match = torch.argmax(torch.abs(dot_product), dim=1)\n",
    "t1_start = rearrange(t1_dictionary[idx_best_match], '(y x)->1 1 y x', y=n_y, x=n_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cce759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum absolute value observed is a good approximation for m0\n",
    "m0_start = torch.amax(torch.abs(idata_multi_ti.data), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d69c2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the starting values\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 2), squeeze=False)\n",
    "colorbar_ax = [make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05) for ax in axes[0, :]]\n",
    "im = axes[0, 0].imshow(m0_start[0, 0, ...])\n",
    "axes[0, 0].set_title('$M_0$ start values')\n",
    "fig.colorbar(im, cax=colorbar_ax[0])\n",
    "im = axes[0, 1].imshow(t1_start[0, 0, ...], vmin=0, vmax=2.5)\n",
    "axes[0, 1].set_title('$T_1$ start values')\n",
    "fig.colorbar(im, cax=colorbar_ax[1], label='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32270769",
   "metadata": {},
   "source": [
    "### Carry out fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f457f649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters for optimizer\n",
    "max_iter = 2000\n",
    "lr = 1e-1\n",
    "\n",
    "# Run optimization\n",
    "params_result = adam(functional, [m0_start, t1_start], max_iter=max_iter, lr=lr)\n",
    "m0, t1 = (p.detach() for p in params_result)\n",
    "m0[torch.isnan(t1)] = 0\n",
    "t1[torch.isnan(t1)] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e236e4",
   "metadata": {},
   "source": [
    "### Visualize the final results\n",
    "To get an impression of how well the fit has worked, we are going to calculate the relative error between\n",
    "\n",
    "$E_{relative} = \\sum_{TI}\\frac{|(q(M_0, T_1, TI) - x)|}{|x|}$\n",
    "\n",
    "on a voxel-by-voxel basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934e1423",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "img_mult_te_abs_sum = torch.sum(torch.abs(idata_multi_ti.data), dim=0)\n",
    "relative_absolute_error = torch.sum(torch.abs(model(m0, t1)[0] - idata_multi_ti.data), dim=0) / (\n",
    "    img_mult_te_abs_sum + 1e-9\n",
    ")\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 2), squeeze=False)\n",
    "colorbar_ax = [make_axes_locatable(ax).append_axes('right', size='5%', pad=0.05) for ax in axes[0, :]]\n",
    "im = axes[0, 0].imshow(m0[0, 0, ...])\n",
    "axes[0, 0].set_title('$M_0$')\n",
    "fig.colorbar(im, cax=colorbar_ax[0])\n",
    "im = axes[0, 1].imshow(t1[0, 0, ...], vmin=0, vmax=2.5)\n",
    "axes[0, 1].set_title('$T_1$')\n",
    "fig.colorbar(im, cax=colorbar_ax[1], label='s')\n",
    "im = axes[0, 2].imshow(relative_absolute_error[0, 0, ...], vmin=0, vmax=1.0)\n",
    "axes[0, 2].set_title('Relative error')\n",
    "fig.colorbar(im, cax=colorbar_ax[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea6e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean-up by removing temporary directory\n",
    "shutil.rmtree(data_folder)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
