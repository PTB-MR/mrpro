{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd286a9c",
   "metadata": {},
   "source": [
    "# Reconstruction of 2D cartesian data from siemens sequence\n",
    "\n",
    "Copyright 2023 Physikalisch-Technische Bundesanstalt\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "  you may not use this file except in compliance with the License.\n",
    "  You may obtain a copy of the License at\n",
    "      http://www.apache.org/licenses/LICENSE-2.0\n",
    "  Unless required by applicable law or agreed to in writing, software\n",
    "  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "  See the License for the specific language governing permissions and\n",
    "  limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c828f",
   "metadata": {},
   "source": [
    "If you want to run this notebook in binder you need to still install the MRpro package.\n",
    "This only needs to be done once in a binder session. Open a terminal (File -> New -> Terminal) and run:\n",
    "```\n",
    "pip install -e \".[notebook]\"\n",
    "```\n",
    "This will install the MRpro package. Any other required python packages should already be present in this\n",
    "docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1081e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from mrpro.data import CsmData\n",
    "from mrpro.data import IData\n",
    "from mrpro.data import KData\n",
    "from mrpro.data.traj_calculators import KTrajectoryCartesian\n",
    "from mrpro.operators import CartesianSamplingOp\n",
    "from mrpro.operators import FourierOp\n",
    "from mrpro.operators import SensitivityOp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9567839",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "data_folder = Path(R'/echo/_allgemein/projects/8_13/MRPro/2024_03_19/siemens_data/2D_cartesian')\n",
    "fnames = list(data_folder.glob('*.h5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb208cc3",
   "metadata": {},
   "source": [
    "## Image reconstruction\n",
    "Image reconstruction involves the following steps:\n",
    "- Reading in the raw data and the trajectory from the ismrmrd raw data file\n",
    "- Calculating the density compensation function (dcf)\n",
    "- Reconstructing one image averaging over the entire relaxation period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4b3298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data and trajectory\n",
    "image_list = []\n",
    "title_list = []\n",
    "header_list = []\n",
    "\n",
    "for fname in fnames:\n",
    "    kdata = KData.from_file(data_folder / fname, KTrajectoryCartesian())\n",
    "\n",
    "    # Reconstruct average image for coil map estimation\n",
    "    Sop = CartesianSamplingOp(kdata.header.encoding_matrix, kdata.traj)\n",
    "    fourier_op = FourierOp(\n",
    "        recon_matrix=kdata.header.recon_matrix, encoding_matrix=kdata.header.encoding_matrix, traj=kdata.traj\n",
    "    )\n",
    "    (img,) = fourier_op.adjoint(Sop.adjoint(kdata.data)[0])\n",
    "    print(img.shape)\n",
    "\n",
    "    # Calculate coilmaps\n",
    "    idata = IData.from_tensor_and_kheader(img, kdata.header)\n",
    "    csm = CsmData.from_idata_walsh(idata)\n",
    "    csm_op = SensitivityOp(csm)\n",
    "\n",
    "    # Coil combination\n",
    "    (img,) = csm_op.adjoint(img)\n",
    "\n",
    "    title_list.append(fname.name.replace('2D_cart_', ''))\n",
    "    image_list.append(torch.squeeze(img))\n",
    "    header_list.append(idata.header)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f21eb8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Data in pixel coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9105927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = len(image_list)\n",
    "n_cols = 2\n",
    "n_rows = int(torch.ceil(torch.tensor((n_images) / n_cols)))\n",
    "plt.subplots(n_rows, n_cols)\n",
    "for i, img in enumerate(image_list):\n",
    "    plt.subplot(n_rows, n_cols, i + 1)\n",
    "    plt.title(title_list[i])\n",
    "\n",
    "    if img.dim() == 3:\n",
    "        img = img[0]\n",
    "\n",
    "    res_x = header_list[i].fov.x / img.shape[0]\n",
    "    res_y = header_list[i].fov.y / img.shape[1]\n",
    "\n",
    "    n_rows_img = torch.tensor(img.shape[0])\n",
    "    n_cols_img = torch.tensor(img.shape[1])\n",
    "\n",
    "    plt.imshow(\n",
    "        torch.abs(img),\n",
    "        interpolation=None,\n",
    "        extent=(\n",
    "            -float(torch.floor(n_cols_img / 2) - 0.5),\n",
    "            float(torch.ceil(n_cols_img / 2) - 0.5),\n",
    "            -float(torch.floor(n_rows_img / 2) - 0.5),\n",
    "            float(torch.ceil(n_rows_img / 2) - 0.5),\n",
    "        ),\n",
    "    )\n",
    "    plt.gca().set_aspect(res_x / res_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12a3ab6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Data in Field of view coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07e5a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = len(image_list)\n",
    "n_cols = 2\n",
    "n_rows = int(torch.ceil(torch.tensor((n_images) / n_cols)))\n",
    "plt.subplots(n_rows, n_cols)\n",
    "for i, img in enumerate(image_list):\n",
    "    plt.subplot(n_rows, n_cols, i + 1)\n",
    "    plt.title(title_list[i])\n",
    "\n",
    "    if img.dim() == 3:\n",
    "        img = img[0]\n",
    "\n",
    "    res_x = header_list[i].fov.x / img.shape[0]\n",
    "    res_y = header_list[i].fov.y / img.shape[1]\n",
    "\n",
    "    n_rows_img = torch.tensor(img.shape[0])\n",
    "    n_cols_img = torch.tensor(img.shape[1])\n",
    "\n",
    "    plt.imshow(\n",
    "        torch.abs(img),\n",
    "        interpolation=None,\n",
    "        extent=(\n",
    "            -header_list[i].fov.x / 2 - res_y / 2,\n",
    "            header_list[i].fov.x / 2 + res_y / 2,\n",
    "            -header_list[i].fov.y / 2 - res_x / 2,\n",
    "            header_list[i].fov.y / 2 + res_x / 2,\n",
    "        ),\n",
    "    )\n",
    "    plt.gca().set_xticks((-header_list[i].fov.x / 2, 0, header_list[i].fov.x / 2))\n",
    "    plt.gca().set_yticks((-header_list[i].fov.y / 2, 0, header_list[i].fov.y / 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040b9eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
