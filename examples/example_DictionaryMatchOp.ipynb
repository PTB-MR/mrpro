{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718689f0",
   "metadata": {},
   "source": [
    "# QMRI Challenge ISMRM 2024 - T1 mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b34a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tempfile\n",
    "import zipfile\n",
    "from collections.abc import Callable\n",
    "from pathlib import Path\n",
    "\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import zenodo_get\n",
    "from einops import rearrange\n",
    "from mrpro.data import IData\n",
    "from mrpro.operators import MagnitudeOp, Operator\n",
    "from mrpro.operators.functionals import MSEDataDiscrepancy\n",
    "from mrpro.operators.models import InversionRecovery\n",
    "from typing_extensions import Self, TypeVarTuple, Unpack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e214996b",
   "metadata": {},
   "source": [
    "### Overview\n",
    "The dataset consists of images obtained at 10 different inversion times using a turbo spin echo sequence. Each\n",
    "inversion time is saved in a separate DICOM file. In order to obtain a T1 map, we are going to:\n",
    "- download the data from Zenodo\n",
    "- read in the DICOM files (one for each inversion time) and combine them in an IData object\n",
    "- define a signal model and data loss (mean-squared error) function\n",
    "- find good starting values for each pixel\n",
    "- carry out a fit using ADAM from PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27705fd2",
   "metadata": {},
   "source": [
    "### Get data from Zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f507de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(tempfile.mkdtemp())\n",
    "dataset = '10868350'\n",
    "zenodo_get.zenodo_get([dataset, '-r', 5, '-o', data_folder])  # r: retries\n",
    "with zipfile.ZipFile(data_folder / Path('T1 IR.zip'), 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba809efe",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Create image data (IData) object with different inversion times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f9d98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ti_dicom_files = data_folder.glob('**/*.dcm')\n",
    "idata_multi_ti = IData.from_dicom_files(ti_dicom_files)\n",
    "\n",
    "if idata_multi_ti.header.ti is None:\n",
    "    raise ValueError('Inversion times need to be defined in the DICOM files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bf24c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at some of the images\n",
    "fig, axes = plt.subplots(1, 3, squeeze=False)\n",
    "for idx, ax in enumerate(axes.flatten()):\n",
    "    ax.imshow(torch.abs(idata_multi_ti.data[idx, 0, 0, :, :]))\n",
    "    ax.set_title(f'TI = {idata_multi_ti.header.ti[idx]:.0f}ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c34ef6d",
   "metadata": {},
   "source": [
    "### Signal model and loss function\n",
    "We use the model $q$\n",
    "\n",
    "$q(TI) = M_0 (1 - e^{-TI/T1})$\n",
    "\n",
    "with the equilibrium magnetization $M_0$, the inversion time $TI$, and $T1$. We have to keep in mind that the DICOM\n",
    "images only contain the magnitude of the signal. Therefore, we need $|q(TI)|$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MagnitudeOp() @ InversionRecovery(ti=idata_multi_ti.header.ti)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14977c61",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "As a loss function for the optimizer, we calculate the mean-squared error between the image data $x$ and our signal\n",
    "model $q$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a522d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = MSEDataDiscrepancy(idata_multi_ti.data.abs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab945d0c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Now we can simply combine the two into a functional to solve\n",
    "\n",
    "$ \\min_{M_0, T1} || |q(M_0, T1, TI)| - x||_2^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21010af",
   "metadata": {},
   "outputs": [],
   "source": [
    "functional = mse @ model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d9b1db",
   "metadata": {},
   "source": [
    "### Starting values for the fit\n",
    "We are trying to minimize a non-linear function $q$. There is no guarantee that we reach the global minimum, but we\n",
    "can end up in a local minimum.\n",
    "\n",
    "To increase our chances of reaching the global minimum, we can ensure that our starting\n",
    "values are already close to the global minimum. We need a good starting point for each pixel.\n",
    "\n",
    "One option to get a good starting point is to calculate the signal curves for a range of T1 values and then check\n",
    "for each pixel which of these signal curves fits best. This is similar to what is done for MR Fingerprinting. So we\n",
    "are going to:\n",
    "- define a list of realistic T1 values (we call this a dictionary of T1 values)\n",
    "- calculate the signal curves corresponding to each of these T1 values\n",
    "- compare the signal curves to the signals of each voxel (we use the maximum of the dot-product as a metric of how\n",
    "well the signals fit to each other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba728fc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Define 100 T1 values between 100 and 3000 ms\n",
    "t1_dictionary = torch.linspace(0.1, 3, 100).double()\n",
    "\n",
    "\n",
    "# Calculate the signal corresponding to each of these T1 values. We set M0 to 1, but this is arbitrary because M0 is\n",
    "# just a scaling factor and we are going to normalize the signal curves.\n",
    "(signal_dictionary,) = model(torch.ones(1), t1_dictionary)\n",
    "signal_dictionary = signal_dictionary +  0j\n",
    "#signal_dictionary = signal_dictionary.to(dtype=torch.complex128)\n",
    "vector_norm = torch.linalg.vector_norm(signal_dictionary, dim=0)\n",
    "signal_dictionary /= vector_norm\n",
    "\n",
    "# Calculate the dot-product and select for each voxel the T1 values that correspond to the maximum of the dot-product\n",
    "n_y, n_x = idata_multi_ti.data.shape[-2:]\n",
    "data = idata_multi_ti.data.to(torch.complex128)\n",
    "dot_product = torch.mm(rearrange(data, 'other 1 z y x->(z y x) other'), signal_dictionary)\n",
    "# print(signal_dictionary)\n",
    "idx_best_match = torch.argmax(torch.abs(dot_product), dim=1)\n",
    "# print(torch.abs(dot_product))\n",
    "t1_start = rearrange(t1_dictionary[idx_best_match], '(y x)->1 1 y x', y=n_y, x=n_x)\n",
    "\n",
    "\n",
    "Tin = TypeVarTuple('Tin')\n",
    "class DictionaryMatchOp(Operator[torch.Tensor, tuple[*Tin]]):\n",
    "    def __init__(self, generating_function: Callable[[Unpack[Tin]], tuple[torch.Tensor,]]):\n",
    "        super().__init__()\n",
    "        self._f = generating_function\n",
    "        self.x: list[torch.Tensor] = []\n",
    "        self.y = torch.tensor([])\n",
    "\n",
    "    def append(self, *x: Unpack[Tin]) -> Self:\n",
    "        (newy,) = self._f(*x)\n",
    "        newy = newy / torch.linalg.norm(newy, dim=0, keepdim=True)\n",
    "        newy = newy.flatten(start_dim=1)\n",
    "        newx = [x.flatten() for x in torch.broadcast_tensors(*x)]\n",
    "        if not self.x:\n",
    "            self.x = newx\n",
    "            self.y = newy\n",
    "            return self\n",
    "        self.x = [torch.cat(old, new) for old, new in zip(self.x, newx, strict=True)]\n",
    "        self.y = torch.cat((self.y, newy))\n",
    "        return\n",
    "\n",
    "    def forward(self, input_signal: torch.Tensor) -> tuple[Unpack[Tin]]:\n",
    "        similar = einops.einsum(input_signal, self.y, 't ..., t idx -> idx ...')\n",
    "        idx = torch.argmax(similar, dim=0)\n",
    "        match=[x[idx] for x in self.x]\n",
    "        return match\n",
    "\n",
    "\n",
    "dict_match_op = DictionaryMatchOp(model)\n",
    "dictionary = dict_match_op.append(torch.ones(1), t1_dictionary)\n",
    "t1_start_new = dict_match_op.forward(idata_multi_ti.rss().double())[1]\n",
    "(t1_start == t1_start_new).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b84827e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbd2edc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(t1_start.real.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e44d8b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.matshow(t1_start_new.real.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2af924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
