{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fzimmermann89/mr2/blob/main/examples/notebooks/cartesian_reconstruction.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "if not importlib.util.find_spec('mr2'):\n",
    "    %pip install mrtwo[notebooks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Basics of mrtwo and Cartesian reconstructions\n",
    "Here, we are going to have a look at a few basics of mrtwo and reconstruct data acquired with a Cartesian sampling\n",
    "pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this notebook, we are going to explore the `~mr2.data.KData` object and the included header parameters.\n",
    "We will then use an FFT-operator in order to reconstruct data acquired with a Cartesian sampling scheme.\n",
    "We will also reconstruct data  acquired on a Cartesian grid but with partial echo and partial Fourier acceleration.\n",
    "Finally, we will reconstruct a Cartesian scan with regular undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show download details"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Get the raw data from zenodo\n",
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import zenodo_get\n",
    "\n",
    "tmp = tempfile.TemporaryDirectory()  # RAII, automatically cleaned up\n",
    "data_folder = Path(tmp.name)\n",
    "zenodo_get.download(\n",
    "    record='15223816',\n",
    "    retry_attempts=5,\n",
    "    output_dir=data_folder,\n",
    "    file_glob=('*.mrd',),\n",
    "    access_token=os.environ.get('ZENODO_TOKEN'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "We have three different scans obtained from the same object with the same FOV and resolution, saved as ISMRMRD\n",
    "raw data files (``*.mrd`` or ``*.h5``):\n",
    "\n",
    "- ``cart_t1.mrd`` is a fully sampled Cartesian acquisition\n",
    "\n",
    "- ``cart_t1_msense_integrated.mrd`` is accelerated using regular undersampling and self-calibrated SENSE\n",
    "\n",
    "- ``cart_t1_partial_echo_partial_fourier.mrd`` is accelerated using partial echo and partial Fourier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Read in raw data and explore header\n",
    "\n",
    "To read in an ISMRMRD file, we can simply pass on the file name to a `~mr2.data.KData` object.\n",
    "Additionally, we need to provide information about the trajectory. In mrtwo, this is done using trajectory\n",
    "calculators. These are functions that calculate the trajectory based on the acquisition information and additional\n",
    "parameters provided to the calculators (e.g. the angular step for a radial acquisition).\n",
    "\n",
    "In this case, we have a Cartesian acquisition. This means that we only need to provide a Cartesian trajectory\n",
    "calculator `~mr2.data.traj_calculators.KTrajectoryCartesian` without any further parameters.\n",
    "\n",
    "See <project:comparison_trajectory_calculators.ipynb> for more information about different ways to\n",
    "define the trajectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mr2\n",
    "\n",
    "kdata = mr2.data.KData.from_file(\n",
    "    data_folder / 'cart_t1.mrd',\n",
    "    mr2.data.traj_calculators.KTrajectoryCartesian(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Now we can explore this data object.\n",
    "Simply printing ``kdata`` gives us a basic overview of the `~mr2.data.KData` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": [
     "show-output"
    ]
   },
   "outputs": [],
   "source": [
    "print(kdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "We can also have a look at more specific header information like the 1H Lamor frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Lamor Frequency:', kdata.header.lamor_frequency_proton)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Reconstruction of fully sampled acquisition\n",
    "\n",
    "For the reconstruction of a fully sampled Cartesian acquisition, we can either use a general\n",
    "`~mr2.operators.FourierOp` or manually set up a Fast Fourier Transform (FFT).\n",
    "For demonstration purposes, we first show the manual approach.\n",
    "\n",
    "```{note}\n",
    " Most of the time, you will use the `~mr2.operators.FourierOp` operator, which automatically takes care\n",
    "of choosing  whether to use a FFT or a non-uniform FFT (NUFFT) based on the trajectory.\n",
    "It optionally can be created from a `~mr2.data.KData` object without any further information.\n",
    "```\n",
    "\n",
    "Let's create an FFT-operator `~mr2.operators.FastFourierOp` and apply it to our `~mr2.data.KData` object.\n",
    "Please note that all mrtwo operator work on PyTorch tensors and not on the mrtwo objects directly. Therefore, we have\n",
    "to call the operator on kdata.data. One other important property of mrtwo operators is that they always return a\n",
    "tuple of PyTorch tensors, even if the output is only a single tensor. This is why we use the ``(img,)`` syntax below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_op = mr2.operators.FastFourierOp(dim=(-2, -1))\n",
    "(img,) = fft_op.adjoint(kdata.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Let's have a look at the shape of the obtained tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape:', img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "We can see that the second dimension, which is the coil dimension, is 16. This means we still have a coil resolved\n",
    "dataset (i.e. one image for each coil element). We can use a simply root-sum-of-squares approach to combine them into\n",
    "one. Later, we will do something a bit more sophisticated. We can also see that the x-dimension is 512. This is\n",
    "because in MRI we commonly oversample the readout direction by a factor 2 leading to a FOV twice as large as we\n",
    "actually need. We can either remove this oversampling along the readout direction or we can simply tell the\n",
    "`~mr2.operators.FastFourierOp` to crop the image by providing the correct output matrix size ``recon_matrix``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create FFT-operator with correct output matrix size\n",
    "fft_op = mr2.operators.FastFourierOp(\n",
    "    dim=(-2, -1),\n",
    "    recon_matrix=kdata.header.recon_matrix,\n",
    "    encoding_matrix=kdata.header.encoding_matrix,\n",
    ")\n",
    "\n",
    "(img,) = fft_op.adjoint(kdata.data)\n",
    "print('Shape:', img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Now, we have an image which is 256 x 256 voxel as we would expect. Let's combine the data from the different receiver\n",
    "coils using root-sum-of-squares and then display the image. Note that we usually index from behind in mrtwo\n",
    "(i.e. -1 for the last, -4 for the fourth last (coil) dimension) to allow for more than one 'other' dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show plotting details"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "def show_images(*images: torch.Tensor, titles: list[str] | None = None) -> None:\n",
    "    \"\"\"Plot images.\"\"\"\n",
    "    n_images = len(images)\n",
    "    _, axes = plt.subplots(1, n_images, squeeze=False, figsize=(n_images * 3, 3))\n",
    "    for i in range(n_images):\n",
    "        axes[0][i].imshow(images[i], cmap='gray', vmin=0, vmax=images[i].max() * 0.6)\n",
    "        axes[0][i].axis('off')\n",
    "        if titles:\n",
    "            axes[0][i].set_title(titles[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Combine data from different coils and show magnitude image\n",
    "magnitude_fully_sampled = img.abs().square().sum(dim=-4).sqrt().squeeze()\n",
    "show_images(magnitude_fully_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Great! That was very easy! Let's try to reconstruct the next dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Reconstruction of acquisition with partial echo and partial Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": [
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "kdata_pe_pf = mr2.data.KData.from_file(\n",
    "    data_folder / 'cart_t1_partial_echo_partial_fourier.mrd',\n",
    "    mr2.data.traj_calculators.KTrajectoryCartesian(),\n",
    ")\n",
    "\n",
    "# Create FFT-operator with correct output matrix size\n",
    "fft_op = mr2.operators.FastFourierOp(\n",
    "    dim=(-2, -1),\n",
    "    recon_matrix=kdata.header.recon_matrix,\n",
    "    encoding_matrix=kdata.header.encoding_matrix,\n",
    ")\n",
    "\n",
    "# Reconstruct coil resolved image(s)\n",
    "(img_pe_pf,) = fft_op.adjoint(kdata_pe_pf.data)\n",
    "\n",
    "# Combine data from different coils using root-sum-of-squares\n",
    "magnitude_pe_pf = img_pe_pf.abs().square().sum(dim=-4).sqrt().squeeze()\n",
    "\n",
    "# Plot both images\n",
    "show_images(magnitude_fully_sampled, magnitude_pe_pf, titles=['fully sampled', 'PF & PE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Well, we got an image, but when we compare it to the previous result, it seems like the head has shrunk.\n",
    "Since that's extremely unlikely, there's probably a mistake in our reconstruction.\n",
    "\n",
    "Let's step back and check out the trajectories for both scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kdata.traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "We see that the trajectory has ``kz``, ``ky``, and ``kx`` components. ``kx`` and ``ky`` only vary along one dimension.\n",
    "```{note}\n",
    "This is because mrtwo saves meta data such as trajectories in an efficient way, where dimensions in which the data\n",
    "does not change are often collapsed. The original shape can be obtained by\n",
    "[broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html).\n",
    "```\n",
    "To get the full trajectory as a tensor, we can also just call `~mr2.data.KTrajectory.as_tensor()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the fully sampled trajectory (in blue)\n",
    "full_kz, full_ky, full_kx = kdata.traj.as_tensor()\n",
    "plt.plot(full_ky[0, 0].flatten(), full_kx[0, 0].flatten(), 'ob')\n",
    "\n",
    "# Plot the partial echo and partial Fourier trajectory (in red)\n",
    "full_kz, full_ky, full_kx = kdata_pe_pf.traj.as_tensor()\n",
    "plt.plot(full_ky[0, 0].flatten(), full_kx[0, 0].flatten(), '+r')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "We see that for the fully sampled acquisition, the k-space is covered symmetrically from -256 to 255 along the\n",
    "readout direction and from -128 to 127 along the phase encoding direction. For the acquisition with partial Fourier\n",
    "and partial echo acceleration, this is of course not the case and the k-space is asymmetrical.\n",
    "\n",
    "Our FFT-operator does not know about this and simply assumes that the acquisition is symmetric and any difference\n",
    "between encoding and recon matrix needs to be zero-padded symmetrically.\n",
    "\n",
    "To take the asymmetric acquisition into account and sort the data correctly into a matrix where we can apply the\n",
    "FFT-operator to, we have got the `~mr2.operators.CartesianSamplingOp` in mrtwo. This operator performs\n",
    "sorting based on the k-space trajectory and the dimensions of the encoding k-space.\n",
    "\n",
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "cart_sampling_op = mr2.operators.CartesianSamplingOp(\n",
    "    encoding_matrix=kdata_pe_pf.header.encoding_matrix, traj=kdata_pe_pf.traj\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Now, we first apply the adjoint CartesianSamplingOp and then call the adjoint FFT-operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "(img_pe_pf,) = fft_op.adjoint(cart_sampling_op.adjoint(kdata_pe_pf.data)[0])\n",
    "magnitude_pe_pf = img_pe_pf.abs().square().sum(dim=-4).sqrt().squeeze()\n",
    "\n",
    "show_images(magnitude_fully_sampled, magnitude_pe_pf, titles=['fully sampled', 'PF & PE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Voila! We've got the same brains, and they're the same size!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## More about operators\n",
    "### The Fourier Operator\n",
    "In mrtwo, we have a smart `~mr2.operators.FourierOp` operator, that automatically does the resorting and can\n",
    "handle non-cartesian data as well. For cartesian data, it internally does exactly the two steps we just did manually.\n",
    "The operator can be also be created from an existing `~mr2.data.KData` object\n",
    "This is the recommended way to transform k-space data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fourier_op = mr2.operators.FourierOp.from_kdata(kdata_pe_pf)\n",
    "# no need for an explicit CartesianSamplingOp anymore!\n",
    "(img_pe_pf,) = fourier_op.adjoint(kdata_pe_pf.data)\n",
    "magnitude_pe_pf = img_pe_pf.abs().square().sum(dim=-4).sqrt().squeeze()\n",
    "show_images(magnitude_fully_sampled, magnitude_pe_pf, titles=['fully sampled', 'PF & PE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "That was easy!\n",
    "But wait a second â€” what about all these nice receiver elements of our coil?\n",
    "\n",
    "Here we used a simple root-sum-of-squares approach, which is not the ideal method.\n",
    "Typically, coil sensitivity maps are calculated to combine the data from different coils. In mrtwo, you can do this\n",
    "by calculating coil sensitivity data and then creating a `~mr2.operators.SensitivityOp` to combine the data after\n",
    "image reconstruction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "### Sensitivity Operator\n",
    "We have different options for calculating coil sensitivity maps from the image data of the various coils.\n",
    "Here, we're going to use the Walsh method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate coil sensitivity maps\n",
    "(img_pe_pf,) = fft_op.adjoint(*cart_sampling_op.adjoint(kdata_pe_pf.data))\n",
    "\n",
    "# This algorithms is designed to calculate coil sensitivity maps for each other dimension.\n",
    "csm_data = mr2.algorithms.csm.walsh(img_pe_pf[0, ...], smoothing_width=5)[None, ...]\n",
    "\n",
    "# Create SensitivityOp\n",
    "csm_op = mr2.operators.SensitivityOp(csm_data)\n",
    "\n",
    "# Reconstruct coil-combined image\n",
    "(img_walsh_combined,) = csm_op.adjoint(*fourier_op.adjoint(kdata_pe_pf.data))\n",
    "magnitude_walsh_combined = img_walsh_combined.abs().squeeze()\n",
    "show_images(magnitude_pe_pf, magnitude_walsh_combined, titles=['RSS', 'Adaptive Combination'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "Tada! Now we have taken everything into consideration ðŸŽ‰.\n",
    "\n",
    "When we reconstructed the image, we called the adjoint method of several different operators one after the other. That\n",
    "was a bit cumbersome. To make our life easier, mrtwo allows to combine the operators first, get the adjoint\n",
    "of the composite operator and then later call this adjoint composite operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Operator Composition\n",
    "# Create composite operator\n",
    "adjoint_operator = (fourier_op @ csm_op).H\n",
    "(magnitude_pe_pf,) = adjoint_operator(kdata_pe_pf.data)\n",
    "magnitude_pe_pf = magnitude_pe_pf.abs().squeeze()\n",
    "show_images(magnitude_pe_pf, titles=['PF & PE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "Although we now have got a nice looking image, it was still a bit cumbersome to create it. We had to define several\n",
    "different operators and chain them together. Wouldn't it be nice if this could be done automatically?\n",
    "\n",
    "That is why we also included some top-level reconstruction algorithms in mrtwo. For this whole steps from above,\n",
    "we can simply use a `~mr2.algorithms.reconstruction.DirectReconstruction`.\n",
    "Reconstruction algorithms can be instantiated from only the information in the `~mr2.data.KData` object.\n",
    "\n",
    "In contrast to operators, top-level reconstruction algorithms operate on the data objects of mrtwo, i.e. the input is\n",
    "a `~mr2.data.KData` object and the output is an `~mr2.data.IData` object containing\n",
    "the reconstructed image data. To get its magnitude, we can call the `~mr2.data.IData.rss` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create DirectReconstruction object from KData object\n",
    "direct_recon_pe_pf = mr2.algorithms.reconstruction.DirectReconstruction(kdata_pe_pf)\n",
    "\n",
    "# Reconstruct image by calling the DirectReconstruction object\n",
    "idat_pe_pf = direct_recon_pe_pf(kdata_pe_pf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "This is much simpler â€” everything happens in the background, so we don't have to worry about it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "## Reconstruction of undersampled data\n",
    "Let's finally try it on the undersampled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdata_us = mr2.data.KData.from_file(\n",
    "    data_folder / 'cart_t1_msense_integrated.mrd',\n",
    "    mr2.data.traj_calculators.KTrajectoryCartesian(),\n",
    ")\n",
    "direct_recon_us = mr2.algorithms.reconstruction.DirectReconstruction(kdata_us)\n",
    "idat_us = direct_recon_us(kdata_us)\n",
    "\n",
    "show_images(idat_pe_pf.rss().squeeze(), idat_us.rss().squeeze(), titles=['PE & PF', 'Undersampled'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Using Calibration Data\n",
    "We used the same data for coil sensitivity calculation as for image reconstruction (*auto-calibration*).\n",
    "Another approach is to acquire a few calibration lines in the center of k-space to create a low-resolution,\n",
    "fully sampled image. In our example data from Siemens scanners, these lines are part of the dataset.\n",
    "As they aren't meant to be used for image reconstruction, only for calibration, i.e., coil sensitivity calculation,\n",
    "and are labeled in the data as such, they are ignored by the default `acquisition_filter_criterion` of\n",
    "`~mr2.data.KData.from_file`.\n",
    "However, we can change the filter criterion to `is_coil_calibration_acquisition` to read in only these acquisitions.\n",
    "\n",
    "```{note}\n",
    "There are already some other filter criteria available, see `mr2.data.acq_filters`. You can also implement your own\n",
    "function returning whether to include an acquisition.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "kdata_calib_lines = mr2.data.KData.from_file(\n",
    "    data_folder / 'cart_t1_msense_integrated.mrd',\n",
    "    mr2.data.traj_calculators.KTrajectoryCartesian(),\n",
    "    acquisition_filter_criterion=mr2.data.acq_filters.is_coil_calibration_acquisition,\n",
    ")\n",
    "\n",
    "direct_recon_calib_lines = mr2.algorithms.reconstruction.DirectReconstruction(kdata_calib_lines)\n",
    "idat_calib_lines = direct_recon_calib_lines(kdata_calib_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "If we look at the reconstructed image, we see it is low resolution.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(idat_calib_lines.rss().squeeze(), titles=['Calibration Image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "..but it is good enough to calculate coil sensitivity maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coil sensitivity maps\n",
    "assert direct_recon_calib_lines.csm is not None\n",
    "show_images(\n",
    "    *direct_recon_calib_lines.csm.data[0].abs().squeeze(),\n",
    "    titles=[f'|CSM {i}|' for i in range(direct_recon_calib_lines.csm.data.size(-4))],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "```{note}\n",
    "There are already some other filter criteria available, see `mr2.data.acq_filters`. You can also implement your own\n",
    "function describing which acquisitions to include.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "### Reconstruction\n",
    "We can now use these CSMs in a new `~mr2.algorithms.reconstruction.DirectReconstruction`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_recon_us_csm = mr2.algorithms.reconstruction.DirectReconstruction(kdata_us, csm=direct_recon_calib_lines.csm)\n",
    "idat_us_csm = direct_recon_us_csm(kdata_us)\n",
    "show_images(idat_us.rss().squeeze(), idat_us_csm.rss().squeeze(), titles=['Autocalibration', 'Calibration Lines'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "As expected, we still see undersampling artifacts in the image. In order to get rid of them,\n",
    "we try can a more sophisticated reconstruction method, such as the *iterative SENSE algorithm*.\n",
    "As you might have guessed, these are also included in mrtwo:\n",
    "Instead of the `~mr2.algorithms.reconstruction.DirectReconstruction`,\n",
    "we can use `~mr2.algorithms.reconstruction.IterativeSENSEReconstruction`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_recon_us = mr2.algorithms.reconstruction.IterativeSENSEReconstruction(\n",
    "    kdata_us,\n",
    "    csm=direct_recon_calib_lines.csm,\n",
    "    n_iterations=8,\n",
    ")\n",
    "idat_us_sense = sense_recon_us(kdata_us)\n",
    "show_images(idat_us_sense.rss().squeeze(), titles=['Iterative SENSE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "This looks better! More information about the iterative SENSE reconstruction and its implementation in mrtwo\n",
    "can be found in the examples <project:iterative_sense_reconstruction_radial2D.ipynb> and\n",
    "<project:iterative_sense_reconstruction_with_regularization.ipynb>.\n",
    "```{note}\n",
    "In this example, we used an \"integrated\" calibration scan, which means that the data used for calibration are acquired\n",
    "with the same parameters (e.g. FOV and resolution) as the image data. There is also the option to use separately\n",
    "acquired calibration lines. Usually, they are acquired with a different resolution and hence have a different\n",
    "k-space range than the image data. To utilize them, the encoding limits have to be adapted manually.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "We can also compare our reconstruction to the reconstruction done on the scanner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download dicom image\n",
    "zenodo_get.download(\n",
    "    record='15223816',\n",
    "    retry_attempts=5,\n",
    "    output_dir=data_folder,\n",
    "    file_glob=('*.dcm',),\n",
    "    access_token=os.environ.get('ZENODO_TOKEN'),\n",
    ")\n",
    "\n",
    "idat_dcm = mr2.data.IData.from_dicom_files(data_folder / 'cart_t1_msense_integrated.dcm')\n",
    "show_images(idat_us_sense.rss().squeeze(), torch.fliplr(idat_dcm.rss().squeeze()), titles=['mrtwo', 'Scanner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "The mrtwo reconstruction shows some residual intensity variations due to the multi-coil acquisition. For the vendor\n",
    "reconstruction this has been compensated for by using an additional scan with the body coil. This is not yet available\n",
    "in mrtwo but all the building blocks are there to implement it. We look forward to your contribution!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "mystnb,tags,-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
