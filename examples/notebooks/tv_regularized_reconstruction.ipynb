{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PTB-MR/mrpro/blob/main/examples/notebooks/tv_regularized_reconstruction.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "if not importlib.util.find_spec('mrpro'):\n",
    "    %pip install mrpro[notebook]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# TV-regularized reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import zenodo_get\n",
    "from mrpro.algorithms.reconstruction import (\n",
    "    DirectReconstruction,\n",
    "    RegularizedIterativeSENSEReconstruction,\n",
    "    TotalVariationDenoising,\n",
    "    TotalVariationRegularizedReconstruction,\n",
    ")\n",
    "from mrpro.data import CsmData, IData, KData\n",
    "from mrpro.data.traj_calculators import KTrajectoryIsmrmrd\n",
    "from mrpro.operators import FiniteDifferenceOp\n",
    "from mrpro.utils import split_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show plotting details"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def show_dynamic_images(img: torch.Tensor, vmin: float = 0, vmax: float = 0.8, title: str | None = None) -> None:\n",
    "    \"\"\"Show a few time frames of the dynamic images and a plot along time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img\n",
    "        image tensor to be displayed\n",
    "    vmin\n",
    "        vmin for display\n",
    "    vmax\n",
    "        vmax for display\n",
    "    title\n",
    "        figure title\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 4, squeeze=False, figsize=(16, 4))\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "    for cax in ax.flatten():\n",
    "        cax.axis('off')\n",
    "    img = img / img.max()\n",
    "    for jnd in range(4):\n",
    "        if jnd == 3:\n",
    "            ax[0, jnd].imshow(\n",
    "                torch.squeeze(img[..., img.shape[-1] // 2]), vmin=vmin, vmax=vmax, cmap='gray', aspect='auto'\n",
    "            )\n",
    "            ax[0, jnd].set_title('Temporal profile')\n",
    "        else:\n",
    "            ax[0, jnd].imshow(torch.squeeze(img[jnd, ...]), vmin=vmin, vmax=vmax, cmap='gray')\n",
    "            ax[0, jnd].set_title(f'Frame {jnd}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "#### Prepare data\n",
    "First, download and read-in the raw data. Then reconstruct coil-resolved images which are used to estimate the coil\n",
    "sensitivity maps. Finally, split the data into different dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download raw data in ISMRMRD format from zenodo into a temporary directory\n",
    "dataset = '13207352'\n",
    "\n",
    "tmp = tempfile.TemporaryDirectory()  # RAII, automatically cleaned up\n",
    "data_folder = Path(tmp.name)\n",
    "zenodo_get.zenodo_get([dataset, '-r', 5, '-o', data_folder])  # r: retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data and trajectory\n",
    "kdata = KData.from_file(data_folder / '2D_GRad_map_t1.h5', KTrajectoryIsmrmrd())\n",
    "\n",
    "\n",
    "# Calculate coil maps\n",
    "reconstruction = DirectReconstruction(kdata, csm=None)\n",
    "csm = CsmData.from_idata_walsh(reconstruction(kdata))\n",
    "\n",
    "# Split data into dynamics\n",
    "idx_dynamic = split_idx(torch.argsort(kdata.header.acq_info.acquisition_time_stamp[0, 0, :, 0]), 30, 0)\n",
    "kdata_dynamic = kdata.split_k1_into_other(idx_dynamic, other_label='repetition')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "#### Direct reconstruction\n",
    "Reconstruct dynamic images using the adjoint of the acquisition operator and sampling density compensation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "direct_reconstruction = DirectReconstruction(kdata_dynamic, csm=csm)\n",
    "img_direct = direct_reconstruction(kdata_dynamic)\n",
    "show_dynamic_images(img_direct.rss())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "#### TV-regularized reconstruction using PDHG\n",
    "Reconstruct images by solving\n",
    "\n",
    "$ \\mathcal{F}(x) = \\frac{1}{2}||Ex - y||_2^2 + \\lambda \\| \\nabla x \\|_1 $\n",
    "\n",
    "using PDHG.\n",
    "\n",
    "Because we have 2D dynamic images, we can apply the TV-regularization along x,y and time.\n",
    "For this we set the regularization weight along dimensions -1 (x), -2 (y) and -5 (time).\n",
    "\n",
    "For this data we chose the regularization along space and time as 5e-6.\n",
    "\n",
    "For more information on this reconstruction method have a look at <project:tv_minimization_reconstruction_pdhg.ipynb>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization_weight_space = 5e-6\n",
    "regularization_weight_time = 5e-6\n",
    "tv_reconstruction = TotalVariationRegularizedReconstruction(\n",
    "    kdata_dynamic,\n",
    "    csm=csm,\n",
    "    max_iterations=100,\n",
    "    regularization_weight=(regularization_weight_time, 0, 0, regularization_weight_space, regularization_weight_space),\n",
    ")\n",
    "img_tv = tv_reconstruction(kdata_dynamic)\n",
    "show_dynamic_images(img_tv.rss())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### TV-regularized reconstruction using ADMM\n",
    "In the above example, PDHG repeatedly applies the acquisition operator and its adjoint during the iterations, which\n",
    "is computationally demanding and hence takes a long time. Another option is to use the Alternating Direction Method\n",
    "of Multipliers (ADMM) [[S. Boyd et al, 2011](http://dx.doi.org/10.1561/2200000016)], which solves the general problem\n",
    "\n",
    "$ \\min_x f(x) + g(z) \\quad \\text{subject to} \\quad  Ax + Bz = c $\n",
    "\n",
    "If we use $f(x) = \\lambda \\| \\nabla x \\|_1$, $g(z)= \\frac{1}{2}||Ez - y||_2^2$, $A = I$, $B= -I$ and $c = 0$\n",
    "\n",
    "then we can define a scaled form of the ADMM algorithm which solves\n",
    "\n",
    "$ \\mathcal{F}(x) = \\frac{1}{2}||Ex - y||_2^2 + \\lambda \\| \\nabla x \\|_1 $\n",
    "\n",
    "by doing\n",
    "\n",
    "$x_{k+1} = \\argmin_x \\lambda \\| \\nabla x \\|_1 + \\frac{\\rho}{2}||x - z_k + u_k||_2^2$\n",
    "\n",
    "$z_{k+1} = \\argmin_z \\frac{1}{2}||Ez - y||_2^2 + \\frac{\\rho}{2}||x_{k+1} - z + u_k||_2^2$\n",
    "\n",
    "$u_{k+1} = u_k + x_{k+1} - z_{k+1}$\n",
    "\n",
    "The first step is TV-based denoising of $x$, the second step is a regularized iterative SENSE update of $z$ and the\n",
    "final step updates the dual variable $u$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "data_weight = 0.5\n",
    "n_admm_iterations = 4\n",
    "tv_denoising = TotalVariationDenoising(\n",
    "    regularization_weight=(\n",
    "        regularization_weight_time / data_weight,\n",
    "        0,\n",
    "        0,\n",
    "        regularization_weight_space / data_weight,\n",
    "        regularization_weight_space / data_weight,\n",
    "    ),\n",
    "    max_iterations=100,\n",
    ")\n",
    "regularized_iterative_sense = RegularizedIterativeSENSEReconstruction(\n",
    "    kdata_dynamic, csm=csm, n_iterations=20, regularization_weight=data_weight\n",
    ")\n",
    "regularized_iterative_sense.dcf = None\n",
    "\n",
    "img_z = img_direct.clone()\n",
    "img_x = img_direct.clone()\n",
    "img_u = torch.zeros_like(img_direct.data)\n",
    "for _ in range(n_admm_iterations):\n",
    "    # Denoising\n",
    "    tv_denoising.initial_image = img_x.data\n",
    "    img_x = tv_denoising(IData(img_z.data - img_u, img_direct.header))\n",
    "\n",
    "    # Regularized iterative SENSE\n",
    "    regularized_iterative_sense.regularization_data = img_x.data + img_u\n",
    "    img_z = regularized_iterative_sense(kdata_dynamic)\n",
    "\n",
    "    # Update u\n",
    "    img_u = img_u + img_x.data - img_z.data\n",
    "\n",
    "show_dynamic_images(img_x.rss(), title='ADMM 1: x')\n",
    "show_dynamic_images(img_z.rss(), title='ADMM 1: z')\n",
    "show_dynamic_images(img_u.abs(), title='ADMM 1: u')\n",
    "\n",
    "img_tv_admm = img_z.rss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### TV-regularized reconstruction using ADMM\n",
    "Another option which avoids pdhg altogether is to use\n",
    "\n",
    "$f(x) = \\lambda \\| x \\|_1$, $g(z)= \\frac{1}{2}||Ez - y||_2^2$, $A = I$, $B= -\\nabla$ and $c = 0$\n",
    "\n",
    "then we can define a scaled form of the ADMM algorithm which solves\n",
    "\n",
    "$ \\mathcal{F}(x) = \\frac{1}{2}||Ex - y||_2^2 + \\lambda \\| \\nabla x \\|_1 $\n",
    "\n",
    "by doing\n",
    "\n",
    "$x_{k+1} = \\argmin_x \\lambda \\| x \\|_1 + \\frac{\\rho}{2}||x - \\nabla z_k + u_k||_2^2$\n",
    "\n",
    "$z_{k+1} = \\argmin_z \\frac{1}{2}||Ez - y||_2^2 + \\frac{\\rho}{2}||x_{k+1} - \\nabla z + u_k||_2^2$\n",
    "\n",
    "$u_{k+1} = u_k + x_{k+1} - \\nabla z_{k+1}$\n",
    "\n",
    "The first step is soft-thresholding of $x$: $S_{\\lambda/\\rho}(\\nabla z_k - u_k)$, the second step is a regularized\n",
    "iterative SENSE update of $z$ and the final step updates the dual variable $u$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "nabla_operator = FiniteDifferenceOp(dim=(0, -2, -1), mode='forward')\n",
    "data_weight = 0.5\n",
    "regularization_weight = regularization_weight_time / (data_weight)\n",
    "\n",
    "regularized_iterative_sense = RegularizedIterativeSENSEReconstruction(\n",
    "    kdata_dynamic,\n",
    "    csm=csm,\n",
    "    n_iterations=10,\n",
    "    regularization_weight=data_weight,\n",
    "    regularization_op=nabla_operator,\n",
    ")\n",
    "regularized_iterative_sense.dcf = None\n",
    "\n",
    "img_z = img_direct.clone()\n",
    "img_u = torch.zeros_like(img_direct.data)\n",
    "for _ in range(n_admm_iterations):\n",
    "    # Denoising by soft-thresholding\n",
    "    img_x_nabla = torch.view_as_complex(\n",
    "        torch.nn.functional.softshrink(torch.view_as_real(nabla_operator(img_z.data)[0] - img_u), regularization_weight)\n",
    "    )\n",
    "\n",
    "    # Regularized iterative SENSE\n",
    "    regularized_iterative_sense.regularization_data = img_x_nabla + img_u\n",
    "    img_z = regularized_iterative_sense(kdata_dynamic)\n",
    "\n",
    "    # Update u\n",
    "    img_u = img_u + img_x_nabla - nabla_operator(img_z.data)[0]\n",
    "\n",
    "\n",
    "show_dynamic_images(torch.sqrt(torch.sum(img_x_nabla**2, dim=0)).abs(), title='ADMM 2: x')\n",
    "show_dynamic_images(img_z.rss(), title='ADMM 2: z')\n",
    "show_dynamic_images(torch.sqrt(torch.sum(img_u**2, dim=0)).abs(), title='ADMM 2: u')\n",
    "\n",
    "img_tv_admm_nabla = img_z.rss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "#### Compare different approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_dynamic_images(img_direct.rss(), title='Direct')\n",
    "show_dynamic_images(img_tv.rss(), title='PDHG')\n",
    "show_dynamic_images(img_tv_admm, title='ADMM 1')\n",
    "show_dynamic_images(img_tv_admm_nabla, title='ADMM 2')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "mystnb,tags,-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
