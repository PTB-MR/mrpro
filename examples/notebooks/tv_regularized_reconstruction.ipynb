{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccff95cb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PTB-MR/mrpro/blob/main/examples/notebooks/tv_regularized_reconstruction.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f5df82",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "if not importlib.util.find_spec('mrpro'):\n",
    "    %pip install mrpro[notebook]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8364401b",
   "metadata": {},
   "source": [
    "# TV-regularized reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe0b944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import zenodo_get\n",
    "from mrpro.algorithms.reconstruction import (\n",
    "    DirectReconstruction,\n",
    "    RegularizedIterativeSENSEReconstruction,\n",
    "    TotalVariationDenoising,\n",
    "    TotalVariationRegularizedReconstruction,\n",
    ")\n",
    "from mrpro.data import CsmData, IData, KData\n",
    "from mrpro.data.traj_calculators import KTrajectoryIsmrmrd\n",
    "from mrpro.operators import FiniteDifferenceOp\n",
    "from mrpro.utils import split_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757a6675",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show plotting details"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def show_dynamic_images(img: torch.Tensor, vmin: float = 0, vmax: float = 0.8) -> None:\n",
    "    \"\"\"Show a few time frames of the dynamic images and a plot along time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img\n",
    "        image tensor to be displayed\n",
    "    vmin\n",
    "        vmin for display\n",
    "    vmax\n",
    "        vmax for display\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 4, squeeze=False, figsize=(16, 4))\n",
    "    for cax in ax.flatten():\n",
    "        cax.axis('off')\n",
    "    img = img / img.max()\n",
    "    for jnd in range(4):\n",
    "        if jnd == 3:\n",
    "            ax[0, jnd].imshow(\n",
    "                torch.squeeze(img[..., img.shape[-1] // 2]), vmin=vmin, vmax=vmax, cmap='gray', aspect='auto'\n",
    "            )\n",
    "            ax[0, jnd].set_title('Temporal profile')\n",
    "        else:\n",
    "            ax[0, jnd].imshow(torch.squeeze(img[jnd, ...]), vmin=vmin, vmax=vmax, cmap='gray')\n",
    "            ax[0, jnd].set_title(f'Frame {jnd}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46248111",
   "metadata": {},
   "source": [
    "#### Prepare data\n",
    "First, download and read-in the raw data. Then reconstruct coil-resolved images which are used to estimate the coil\n",
    "sensitivity maps. Finally, split the data into different dynamics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a92691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download raw data in ISMRMRD format from zenodo into a temporary directory\n",
    "if False:\n",
    "    dataset = '13207352'\n",
    "\n",
    "    tmp = tempfile.TemporaryDirectory()  # RAII, automatically cleaned up\n",
    "    data_folder = Path(tmp.name)\n",
    "    zenodo_get.zenodo_get([dataset, '-r', 5, '-o', data_folder])  # r: retries\n",
    "else:\n",
    "    data_folder = Path('/Users/kolbit01/Documents/Data/mrpro/raw/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0243855a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data and trajectory\n",
    "kdata = KData.from_file(data_folder / '2D_GRad_map_t1.h5', KTrajectoryIsmrmrd())\n",
    "\n",
    "\n",
    "# Calculate coil maps\n",
    "reconstruction = DirectReconstruction(kdata, csm=None)\n",
    "csm = CsmData.from_idata_walsh(reconstruction(kdata))\n",
    "\n",
    "# Split data into dynamics\n",
    "idx_dynamic = split_idx(torch.argsort(kdata.header.acq_info.acquisition_time_stamp[0, 0, :, 0]), 30, 0)\n",
    "kdata_dynamic = kdata.split_k1_into_other(idx_dynamic, other_label='repetition')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49938d1",
   "metadata": {},
   "source": [
    "#### Direct reconstruction\n",
    "Reconstruct dynamic images using the adjoint of the acquisition operator and sampling density compensation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8139d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_reconstruction = DirectReconstruction(kdata_dynamic, csm=csm)\n",
    "img_direct = direct_reconstruction(kdata_dynamic)\n",
    "show_dynamic_images(img_direct.rss())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f20ba8",
   "metadata": {},
   "source": [
    "#### TV-regularized reconstruction using PDHG\n",
    "Reconstruct images by solving\n",
    "\n",
    "$ \\mathcal{F}(x) = \\frac{1}{2}||Ax - y||_2^2 + \\lambda \\| \\nabla x \\|_1 $\n",
    "\n",
    "using PDHG.\n",
    "\n",
    "Because we have 2D dynamic images we can apply the TV-regularization along x,y and time.\n",
    "For this we set the regularization weight along dimensions -1 (x), -2 (y) and -5 (time).\n",
    "\n",
    "For more information on this reconstruction method have a look at the tv_minimization_reconstruction_pdhg example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb50ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_reconstruction = TotalVariationRegularizedReconstruction(\n",
    "    kdata_dynamic, csm=csm, n_iterations=100, regularization_weight=(0.1, 0, 0, 0.1, 0.1)\n",
    ")\n",
    "img_tv = tv_reconstruction(kdata_dynamic)\n",
    "show_dynamic_images(img_tv.rss())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdbe84c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "#### TV-regularized reconstruction using ADMM\n",
    "In the above example we need to apply the acquisition operator during the PDHG iterations which is computationally\n",
    "demanding and hence takes a long time. Another option is to use the Alternating Direction Method of Multipliers (ADMM)\n",
    "which solves the general problem\n",
    "\n",
    "$ \\min_x f(x) + g(z) \\quad \\text{subject to} \\quad  Ax + Bz = c $\n",
    "\n",
    "If we use $f(x) = \\lambda \\| \\nabla x \\|_1$, $g(z)= \\frac{1}{2}||Az - y||_2^2$, $A = I$, $B= -I$ and $c = 0$\n",
    "\n",
    "then we can define a scaled form of the ADMM algorithm which solves\n",
    "\n",
    "$ \\mathcal{F}(x) = \\frac{1}{2}||Ax - y||_2^2 + \\lambda \\| \\nabla x \\|_1 $\n",
    "\n",
    "by doing\n",
    "\n",
    "$x_{k+1} = argmin_x \\lambda \\| \\nabla x \\|_1 + \\frac{\\rho}{2}||x - z_k + u_k||_2^2$\n",
    "\n",
    "$z_{k+1} = argmin_z \\frac{1}{2}||Az - y||_2^2 + \\frac{\\rho}{2}||x_{k+1} - z + u_k||_2^2$\n",
    "\n",
    "$u_{k+1} = u_k + x_{k+1} - z_{k+1}$\n",
    "\n",
    "The first step is TV-based denoising of $x$, the second step is a regularized iterative SENSE update of $z$ and the\n",
    "final step updates the helper variable $u$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfc645c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "data_weight = 0.5\n",
    "n_adam_iterations = 4\n",
    "regularization_weight = 0.1 / (data_weight * n_adam_iterations)\n",
    "tv_denoising = TotalVariationDenoising(\n",
    "    regularization_weight=(regularization_weight, 0, 0, regularization_weight, regularization_weight), n_iterations=100\n",
    ")\n",
    "regularized_iterative_sense = RegularizedIterativeSENSEReconstruction(\n",
    "    kdata_dynamic, csm=csm, n_iterations=10, regularization_weight=data_weight\n",
    ")\n",
    "img_z = img_direct.clone()\n",
    "img_x = img_direct.clone()\n",
    "img_u = torch.zeros_like(img_direct.data)\n",
    "for _ in range(n_adam_iterations):\n",
    "    # Denoising\n",
    "    tv_denoising.initial_image = img_x.data\n",
    "    img_x = tv_denoising(IData(img_z.data - img_u, img_direct.header))\n",
    "\n",
    "    # Regularized iterative SENSE\n",
    "    regularized_iterative_sense.regularization_data = img_x.data + img_u\n",
    "    img_z = regularized_iterative_sense(kdata_dynamic)\n",
    "\n",
    "    # Update u\n",
    "    img_u = img_u + img_x.data - img_z.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5aa20c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "show_dynamic_images(img_x.rss())\n",
    "show_dynamic_images(img_z.rss())\n",
    "show_dynamic_images(torch.sqrt(torch.sum(img_u**2, dim=1)).abs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0c3e7d",
   "metadata": {},
   "source": [
    "#### TV-regularized reconstruction using ADMM\n",
    "Another option which avoids pdhg altogether is to use\n",
    "\n",
    "$f(x) = \\lambda \\| x \\|_1$, $g(z)= \\frac{1}{2}||Az - y||_2^2$, $A = I$, $B= -\\nabla$ and $c = 0$\n",
    "\n",
    "then we can define a scaled form of the ADMM algorithm which solves\n",
    "\n",
    "$ \\mathcal{F}(x) = \\frac{1}{2}||Ax - y||_2^2 + \\lambda \\| \\nabla x \\|_1 $\n",
    "\n",
    "by doing\n",
    "\n",
    "$x_{k+1} = argmin_x \\lambda \\| x \\|_1 + \\frac{\\rho}{2}||x - \\nabla z_k + u_k||_2^2$\n",
    "\n",
    "$z_{k+1} = argmin_z \\frac{1}{2}||Az - y||_2^2 + \\frac{\\rho}{2}||x_{k+1} - \\nabla z + u_k||_2^2$\n",
    "\n",
    "$u_{k+1} = u_k + x_{k+1} - \\nabla z_{k+1}$\n",
    "\n",
    "The first step is soft-thresholding of $x$: $S_{\\lambda/\\rho}(\\nabla z_k - u_k$, the second step is a regularized\n",
    "iterative SENSE update of $z$ and the final step updates the helper variable $u$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd06a58c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "nabla_operator = FiniteDifferenceOp(dim=(0, -2, -1), mode='forward')\n",
    "data_weight = 0.5\n",
    "regularization_weight = 0.00001 / (data_weight * n_adam_iterations)\n",
    "\n",
    "regularized_iterative_sense = RegularizedIterativeSENSEReconstruction(\n",
    "    kdata_dynamic,\n",
    "    csm=csm,\n",
    "    n_iterations=10,\n",
    "    regularization_weight=data_weight,\n",
    "    regularization_op=nabla_operator,\n",
    ")\n",
    "img_z = img_direct.clone()\n",
    "img_u = torch.zeros_like(img_direct.data)\n",
    "for _ in range(n_adam_iterations):\n",
    "    # Denoising by soft-thresholding\n",
    "    img_x_nabla = torch.view_as_complex(\n",
    "        torch.nn.functional.softshrink(\n",
    "            torch.view_as_real(nabla_operator(img_z.data)[0] - img_u), regularization_weight / data_weight\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Regularized iterative SENSE\n",
    "    regularized_iterative_sense.regularization_data = img_x_nabla + img_u\n",
    "    img_z = regularized_iterative_sense(kdata_dynamic)\n",
    "\n",
    "    # Update u\n",
    "    img_u = img_u + img_x_nabla - nabla_operator(img_z.data)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de51688",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "show_dynamic_images(torch.sqrt(torch.sum(img_x_nabla**2, dim=0)).abs())\n",
    "show_dynamic_images(img_z.rss())\n",
    "show_dynamic_images(torch.sqrt(torch.sum(img_u**2, dim=0)).abs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6584ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "mystnb,tags,-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
