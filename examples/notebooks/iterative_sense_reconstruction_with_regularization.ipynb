{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fzimmermann89/mr2/blob/main/examples/notebooks/iterative_sense_reconstruction_with_regularization.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "if not importlib.util.find_spec('mr2'):\n",
    "    %pip install mrtwo[notebooks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Regularized iterative SENSE reconstruction of 2D golden angle radial data\n",
    "Here we use the `~mr2.algorithms.reconstruction.RegularizedIterativeSENSEReconstruction` class to reconstruct\n",
    "undersampled images from 2D radial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show download details"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Download raw data from Zenodo\n",
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import zenodo_get\n",
    "\n",
    "tmp = tempfile.TemporaryDirectory()  # RAII, automatically cleaned up\n",
    "data_folder = Path(tmp.name)\n",
    "zenodo_get.download(\n",
    "    record='14617082', retry_attempts=5, output_dir=data_folder, access_token=os.environ.get('ZENODO_TOKEN')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Image reconstruction\n",
    "We use the `~mr2.algorithms.reconstruction.RegularizedIterativeSENSEReconstruction` class to reconstruct images\n",
    "from 2D radial data. It solves the following reconstruction problem:\n",
    "\n",
    "Let's assume we have obtained the k-space data $y$ from an image $x$ with an acquisition model (Fourier transforms,\n",
    "coil sensitivity maps...) $A$ then we can formulate the forward problem as:\n",
    "\n",
    "$ y = Ax + n $\n",
    "\n",
    "where $n$ describes complex Gaussian noise. The image $x$ can be obtained by minimizing the functional $F$\n",
    "\n",
    "$ F(x) = ||Ax - y||_2^2 + \\lambda||Bx - x_\\mathrm{reg}||_2^2$\n",
    "\n",
    "where $\\lambda$ is the strength of the regularization, $B$ is a linear operator and $x_\\mathrm{reg}$ is a\n",
    "regularization image.\n",
    "With this functional $F$ we obtain a solution which is close to $x_\\mathrm{reg}$ and to the acquired data $y$.\n",
    "\n",
    "Setting the derivative (see https://www.matrixcalculus.org) of the functional $F$ to zero and rearranging yields\n",
    "\n",
    "$ (A^H A + l B^H B) x = A^H y + \\lambda B^H x_\\mathrm{reg}$\n",
    "\n",
    "which is a linear system $Hx = b$ that needs to be solved for $x$.\n",
    "\n",
    "One important question of course is, what to use as $x_\\mathrm{{reg}}$ and $B$. For dynamic images (e.g. cine MRI)\n",
    "low-resolution dynamic images or high-quality static images have been proposed.\n",
    "In recent years, the output of neural networks has also been used, i.e. $x_{\\mathrm{reg}} = u_{\\theta}(x_0)$\n",
    "$B=\\mathrm{Id}$ for a pre-trained network $u_{\\theta}$ and initial image $x_0$ [[Kofler et al. 2020](https://doi.org/10.1088/1361-6560/ab990e)].\n",
    "\n",
    "In this example we are going to use a high-quality image to regularize the reconstruction of an undersampled image.\n",
    "Both images are obtained from the same data acquisition - one using all the acquired data ($x_{\\mathrm{reg}}$),\n",
    "and one using only parts of it ($x$). This is, of course, an unrealistic case but it will allow us to demonstrate\n",
    "the effect of the regularization.\n",
    "\n",
    "```{note}\n",
    "In [Pruessmann et al. 2001](https://doi.org/10.1002/mrm.1241) the k-space density is used to reweight the\n",
    "loss to achieve faster convergence. This increases reconstruction error, see [Ong F., Uecker M., Lustig M. 2020](https://doi.org/10.1109/TMI.2019.2954121).\n",
    "We follow a recommendation by [Fessler and Noll](https://ece-classes.usc.edu/ee591/library/Fessler-Iterative%20Reconstruction.pdf)\n",
    "and use the DCF to obtain a good starting point.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Reading of both fully sampled and undersampled data\n",
    "We read the raw data and the trajectory from the ISMRMRD file.\n",
    "We load both, the fully sampled and the undersampled data.\n",
    "The fully sampled data will be used to estimate the coil sensitivity maps and as a regularization image.\n",
    "The undersampled data will be used to reconstruct the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the raw data and the trajectory from ISMRMRD file\n",
    "import mr2\n",
    "\n",
    "kdata_fullysampled = mr2.data.KData.from_file(\n",
    "    data_folder / 'radial2D_402spokes_golden_angle_with_traj.h5',\n",
    "    mr2.data.traj_calculators.KTrajectoryIsmrmrd(),\n",
    ")\n",
    "kdata_undersampled = mr2.data.KData.from_file(\n",
    "    data_folder / 'radial2D_24spokes_golden_angle_with_traj.h5',\n",
    "    mr2.data.traj_calculators.KTrajectoryIsmrmrd(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "##### Obtain image $x_{\\mathrm{reg}}$ from fully sampled data\n",
    "We first reconstruct the fully sampled image to use it as a regularization image.\n",
    "In a real-world scenario, we would not have this image and would have to use a low-resolution image as a prior, or use\n",
    "a neural network to estimate the regularization image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate coil maps. Here we use the fully sampled data to estimate the coil sensitivity maps.\n",
    "# In a real-world scenario, we would either a calibration scan (e.g. a separate fully sampled scan) to estimate the coil\n",
    "# sensitivity maps or use ESPIRiT or similar methods to estimate the coil sensitivity maps from the undersampled data.\n",
    "direct_reconstruction = mr2.algorithms.reconstruction.DirectReconstruction(kdata_fullysampled)\n",
    "csm_op = direct_reconstruction.csm_op\n",
    "assert csm_op is not None\n",
    "\n",
    "# unregularized iterative SENSE reconstruction of the fully sampled data\n",
    "iterative_sense_reconstruction = mr2.algorithms.reconstruction.IterativeSENSEReconstruction(\n",
    "    kdata_fullysampled, csm=csm_op, n_iterations=3\n",
    ")\n",
    "img_iterative_sense = iterative_sense_reconstruction(kdata_fullysampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "##### Image $x$ from undersampled data\n",
    "We now reconstruct the undersampled image using the fully sampled image first without regularization,\n",
    "and with a regularization image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unregularized iterative SENSE reconstruction of the undersampled data\n",
    "iterative_sense_reconstruction = mr2.algorithms.reconstruction.IterativeSENSEReconstruction(\n",
    "    kdata_undersampled, csm=csm_op, n_iterations=6\n",
    ")\n",
    "img_us_iterative_sense = iterative_sense_reconstruction(kdata_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularized iterative SENSE reconstruction of the undersampled data\n",
    "\n",
    "regularized_iterative_sense_reconstruction = mr2.algorithms.reconstruction.RegularizedIterativeSENSEReconstruction(\n",
    "    kdata_undersampled,\n",
    "    csm=csm_op,\n",
    "    n_iterations=6,\n",
    "    regularization_data=img_iterative_sense.data,\n",
    "    regularization_weight=1.0,\n",
    ")\n",
    "img_us_regularized_iterative_sense = regularized_iterative_sense_reconstruction(kdata_undersampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "##### Display the results\n",
    "Besides the fully sampled image, we display two undersampled images:\n",
    "The first one is obtained by unregularized iterative SENSE, the second one using regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show plotting details"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "def show_images(*images: torch.Tensor, titles: list[str] | None = None) -> None:\n",
    "    \"\"\"Plot images.\"\"\"\n",
    "    n_images = len(images)\n",
    "    _, axes = plt.subplots(1, n_images, squeeze=False, figsize=(n_images * 3, 3))\n",
    "    for i in range(n_images):\n",
    "        axes[0][i].imshow(images[i], cmap='gray')\n",
    "        axes[0][i].axis('off')\n",
    "        if titles:\n",
    "            axes[0][i].set_title(titles[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(\n",
    "    img_iterative_sense.rss()[0, 0],\n",
    "    img_us_iterative_sense.rss()[0, 0],\n",
    "    img_us_regularized_iterative_sense.rss()[0, 0],\n",
    "    titles=['Fully sampled', 'Iterative SENSE R=20', 'Regularized Iterative SENSE R=20'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Behind the scenes\n",
    "We now investigate the steps that are done in the regularized iterative SENSE reconstruction and\n",
    "perform them manually. This also demonstrates how to use the `mr2` operators and algorithms\n",
    "to build your own reconstruction pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "##### Set-up the acquisition model $A$\n",
    "\n",
    "This is very similar to <project:iterative_sense_reconstruction_radial2D.ipynb> .\n",
    "For more details, please refer to that notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier_operator = mr2.operators.FourierOp.from_kdata(kdata_undersampled)\n",
    "csm_operator = csm_op\n",
    "acquisition_operator = fourier_operator @ csm_operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "##### Set-up the right-hand side $b$\n",
    "We calculate $b = A^H y + \\lambda B^H x_\\mathrm{reg}$, using the identity operator as $B$ and $\\lambda = 1.0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization_weight = 1.0\n",
    "regularization_image = img_iterative_sense.data\n",
    "regularization_operator = mr2.operators.IdentityOp()\n",
    "\n",
    "(regularization,) = (regularization_weight * regularization_operator.H)(regularization_image)\n",
    "(right_hand_side,) = (acquisition_operator.H)(kdata_undersampled.data)\n",
    "right_hand_side = right_hand_side + regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "##### Set-up the linear self-adjoint operator $H$\n",
    "We define $H = A^H A + \\lambda B^HB$. We can use `~mr2.operators.LinearOperator.gram` to get an efficient\n",
    "implementation of $A^H A$. We use the `~mr2.operators.IdentityOp` and make\n",
    "use of operator addition using ``+`` and multiplication using ``*``.\n",
    "The resulting operator is a `~mr2.operators.LinearOperator` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "operator = acquisition_operator.gram + mr2.operators.IdentityOp() * regularization_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "##### Run conjugate gradient\n",
    "We solve the linear system $Hx = b$ using the conjugate gradient method.\n",
    "Here we use a density compensated adjoint reconstruction to obtain a good starting point,\n",
    "$x_0 = A^H W y$ with $W$ being the density compensation operator.\n",
    "We use a tolerance of $1e-7$ for the residual as a stopping criterion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcf_operator = mr2.data.DcfData.from_traj_voronoi(kdata_undersampled.traj).as_operator()\n",
    "(initial_value,) = (acquisition_operator.H @ dcf_operator)(kdata_undersampled.data)\n",
    "(img_manual,) = mr2.algorithms.optimizers.cg(operator, right_hand_side, initial_value=initial_value, tolerance=1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "#####  Display the reconstructed image\n",
    "We can now compare our 'manual' reconstruction with the regularized iterative SENSE reconstruction\n",
    "obtained using `~mr2.algorithms.reconstruction.RegularizedIterativeSENSEReconstruction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(\n",
    "    img_us_regularized_iterative_sense.rss()[0, 0],\n",
    "    img_manual.abs()[0, 0, 0],\n",
    "    titles=['RegularizedIterativeSense', 'Manual'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "We can verify the results by comparing the actual image data.\n",
    "If the assert statement does not raise an exception, the results are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(img_us_regularized_iterative_sense.data, img_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "\n",
    "We are cheating here because we used the fully sampled image as a regularization. In real world applications\n",
    "we would not have that. One option is to apply a low-pass filter to the undersampled k-space data to try to reduce the\n",
    "streaking artifacts and use that as a regularization image. Try that and see if you can also improve the image quality\n",
    "compared to the unregularized images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "mystnb,tags,-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
