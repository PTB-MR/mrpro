{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PTB-MR/mrpro/blob/main/examples/notebooks/iterative_sense_reconstruction_with_regularization.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "if not importlib.util.find_spec('mrpro'):\n",
    "    %pip install mrpro[notebook]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Regularized Iterative SENSE Reconstruction of 2D golden angle radial data\n",
    "Here we use the `mrpro.algorithms.reconstruction.RegularizedIterativeSENSEReconstruction` class to reconstruct\n",
    "undersampled images from 2D radial data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Download raw data from Zenodo\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import zenodo_get\n",
    "\n",
    "dataset = '14617082'\n",
    "\n",
    "tmp = tempfile.TemporaryDirectory()  # RAII, automatically cleaned up\n",
    "data_folder = Path(tmp.name)\n",
    "zenodo_get.zenodo_get([dataset, '-r', 5, '-o', data_folder])  # r: retries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Image reconstruction\n",
    "We use the `~mrpro.algorithms.reconstruction.RegularizedIterativeSENSEReconstruction` class to reconstruct images from 2D radial data.\n",
    "It solves the following reconstruction problem:\n",
    "\n",
    "Let's assume we have obtained the k-space data $y$ from an image $x$ with an acquisition model (Fourier transforms,\n",
    "coil sensitivity maps...) $A$ then we can formulate the forward problem as:\n",
    "\n",
    "$ y = Ax + n $\n",
    "\n",
    "where $n$ describes complex Gaussian noise. The image $x$ can be obtained by minimizing the functionl $F$\n",
    "\n",
    "$ F(x) = ||W^{\\frac{1}{2}}(Ax - y)||_2^2 $\n",
    "\n",
    "where $W^\\frac{1}{2}$ is the square root of the density compensation function (which corresponds to a diagonal\n",
    "operator). Because this is an ill-posed problem, we can add a regularization term to stabilize the problem and obtain\n",
    "a solution with certain properties:\n",
    "\n",
    "$ F(x) = ||W^{\\frac{1}{2}}(Ax - y)||_2^2 + l||Bx - x_{reg}||_2^2$\n",
    "\n",
    "where $l$ is the strength of the regularization, $B$ is a linear operator and $x_{reg}$ is a regularization image.\n",
    "With this functional $F$ we obtain a solution which is close to $x_{reg}$ and to the acquired data $y$.\n",
    "\n",
    "Setting the derivative of the functional $F$ to zero and rearranging yields\n",
    "\n",
    "$ (A^H W A + l B) x = A^H W y + l x_{reg}$\n",
    "\n",
    "which is a linear system $Hx = b$ that needs to be solved for $x$.\n",
    "\n",
    "One important question of course is, what to use for $x_{reg}$. For dynamic images (e.g. cine MRI) low-resolution\n",
    "dynamic images or high-quality static images have been proposed. In recent years, also the output of neural-networks\n",
    "has been used as an image regulariser.\n",
    "\n",
    "In this example we are going to use a high-quality image to regularize the reconstruction of an undersampled image.\n",
    "Both images are obtained from the same data acquisition (one using all the acquired data ($x_{reg}$) and one using\n",
    "only parts of it ($x$)). This of course is an unrealistic case but it will allow us to study the effect of the\n",
    "regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "##### Read-in the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Download raw data from Zenodo\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import mrpro\n",
    "import torch\n",
    "import zenodo_get\n",
    "\n",
    "dataset = '14617082'\n",
    "\n",
    "tmp = tempfile.TemporaryDirectory()  # RAII, automatically cleaned up\n",
    "data_folder = Path(tmp.name)\n",
    "zenodo_get.zenodo_get([dataset, '-r', 5, '-o', data_folder])  # r: retries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Reading of both fully sampled and undersampled data\n",
    "This will use the trajectory that is stored in the ISMRMRD file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Read the raw data and the trajectory from ISMRMRD file\n",
    "\n",
    "kdata_fullysampled = mrpro.data.KData.from_file(\n",
    "    data_folder / 'radial2D_402spokes_golden_angle_with_traj.h5',\n",
    "    mrpro.data.traj_calculators.KTrajectoryIsmrmrd(),\n",
    ")\n",
    "kdata_undersampled = mrpro.data.KData.from_file(\n",
    "    data_folder / 'radial2D_24spokes_golden_angle_with_traj.h5',\n",
    "    mrpro.data.traj_calculators.KTrajectoryIsmrmrd(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "##### Image $x_{reg}$ from fully sampled data\n",
    "We first reconstruct the fully sampled image to use it as a regularization image.\n",
    "In a real-world scenario, we would not have this image and would have to use a low-resolution image as a prior, or use\n",
    "a neural network to estimate the regularization image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate coil maps. Here we use the fully sampled data to estimate the coil sensitivity maps.\n",
    "# In a real-world scenario, we would either a calibration scan (e.g. a separate fully sampled scan) to estimate the coil\n",
    "# sensitivity maps or use ESPIRiT or similar methods to estimate the coil sensitivity maps from the undersampled data.\n",
    "direct_reconstruction = mrpro.algorithms.reconstruction.DirectReconstruction(kdata_fullysampled)\n",
    "csm = direct_reconstruction.csm\n",
    "assert csm is not None\n",
    "\n",
    "# unregularized iterative SENSE reconstruction of the fully sampled data\n",
    "iterative_sense_reconstruction = mrpro.algorithms.reconstruction.IterativeSENSEReconstruction(\n",
    "    kdata_fullysampled, csm=csm, n_iterations=3\n",
    ")\n",
    "img_iterative_sense = iterative_sense_reconstruction(kdata_fullysampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "##### Image $x$ from undersampled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unregularized iterative SENSE reconstruction of the undersampled data\n",
    "iterative_sense_reconstruction = mrpro.algorithms.reconstruction.IterativeSENSEReconstruction(\n",
    "    kdata_undersampled, csm=csm, n_iterations=6\n",
    ")\n",
    "img_us_iterative_sense = iterative_sense_reconstruction(kdata_undersampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularized iterativ SENSE reconstruction of the undersampled data\n",
    "\n",
    "regularized_iterative_sense_reconstruction = mrpro.algorithms.reconstruction.RegularizedIterativeSENSEReconstruction(\n",
    "    kdata_undersampled,\n",
    "    csm=csm,\n",
    "    n_iterations=6,\n",
    "    regularization_data=img_iterative_sense.data,\n",
    "    regularization_weight=1.0,\n",
    ")\n",
    "img_us_regularized_iterative_sense = regularized_iterative_sense_reconstruction(kdata_undersampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "##### Display the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def show_images(*images: torch.Tensor, titles: list[str] | None = None) -> None:\n",
    "    \"\"\"Plot images.\"\"\"\n",
    "    n_images = len(images)\n",
    "    _, axes = plt.subplots(1, n_images, squeeze=False, figsize=(n_images * 3, 3))\n",
    "    for i in range(n_images):\n",
    "        axes[0][i].imshow(images[i], cmap='gray')\n",
    "        axes[0][i].axis('off')\n",
    "        if titles:\n",
    "            axes[0][i].set_title(titles[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# vis_im = [img_iterative_sense.rss(), img_us_iterative_sense.rss(), img_us_regularized_iterative_sense.rss()]\n",
    "# vis_title = ['Fully sampled', 'Iterative SENSE R=20', 'Regularized Iterative SENSE R=20']\n",
    "# fig, ax = plt.subplots(1, 3, squeeze=False, figsize=(12, 4))\n",
    "# for ind in range(3):\n",
    "#     ax[0, ind].imshow(vis_im[ind][0, 0, ...])\n",
    "#     ax[0, ind].set_title(vis_title[ind])\n",
    "show_images(\n",
    "    img_iterative_sense.rss()[0, 0],\n",
    "    img_us_iterative_sense.rss()[0, 0],\n",
    "    img_us_regularized_iterative_sense.rss()[0, 0],\n",
    "    titles=['Fully sampled', 'Iterative SENSE R=20', 'Regularized Iterative SENSE R=20'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Behind the scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "##### Set-up the density compensation operator $W$ and acquisition model $A$\n",
    "\n",
    "This is very similar to <project:iterative_sense_reconstruction.ipynb>. For more details, please refer to that notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcf_operator = mrpro.data.DcfData.from_traj_voronoi(kdata_undersampled.traj).as_operator()\n",
    "fourier_operator = mrpro.operators.FourierOp.from_kdata(kdata_undersampled)\n",
    "csm_operator = csm.as_operator()\n",
    "acquisition_operator = fourier_operator @ csm_operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "##### Calculate the right-hand-side of the linear system $b = A^H W y + l x_{reg}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "regularization_weight = 1.0\n",
    "regularization_image = img_iterative_sense.data\n",
    "\n",
    "right_hand_side = (acquisition_operator.H @ dcf_operator(kdata_undersampled.data))[\n",
    "    0\n",
    "] + regularization_weight * regularization_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "##### Set-up the linear self-adjoint operator $H = A^H W A + l$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "operator = (\n",
    "    acquisition_operator.H @ dcf_operator @ acquisition_operator + mrpro.operators.IdentityOp() * regularization_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "##### Run conjugate gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "img_manual = mrpro.algorithms.optimizers.cg(\n",
    "    operator, right_hand_side, initial_value=right_hand_side, max_iterations=8, tolerance=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "#####  Display the reconstructed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "show_images(\n",
    "    img_us_regularized_iterative_sense.rss()[0, 0],\n",
    "    img_manual.abs()[0, 0],\n",
    "    titles=['Regularized Iterative SENSE R=20', '\"Manual\" Regularized Iterative SENSE R=20'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Check for equal results\n",
    "The two versions should result in the same image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the assert statement did not raise an exception, the results are equal.\n",
    "assert torch.allclose(img_us_regularized_iterative_sense.data, img_manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "\n",
    "We are cheating here because we used the fully sampled image as a regularization. In real world applications\n",
    "we would not have that. One option is to apply a low-pass filter to the undersampled k-space data to try to reduce the\n",
    "streaking artifacts and use that as a regularization image. Try that and see if you can also improve the image quality\n",
    "compared to the unregularised images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "tags,-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
