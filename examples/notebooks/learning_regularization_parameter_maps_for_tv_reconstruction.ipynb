{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PTB-MR/mrpro/blob/main/examples/notebooks/learning_regularization_parameter_maps_for_tv_reconstruction.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "if not importlib.util.find_spec('mrpro'):\n",
    "    %pip install mrpro[notebook]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Learning spatially adaptive regularization parameter maps for total-variation (TV)-minimization reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Overview\n",
    "In this notebook, we are going to demonstrate how the method presented in\n",
    "[[Kofler et al, SIIMS 2023](https://epubs.siam.org/doi/abs/10.1137/23M1552486)] can be implemented for\n",
    "2D MR reconstruction problems using MRpro. The method consists of two main blocks.\n",
    "1) The first block is a neural network architecture that estimates spatially adaptive regularization\n",
    "parameter maps, which are then used in 2).\n",
    "2) The second block corresponds to an unrolled unrolled Primal-Dual Hybrid Gradient (PDHG) algorithm to\n",
    "reconstruct an images from undersampled k-space data # measurements assuming the regularization\n",
    "parameter maps are to be fixed.\n",
    "The entire pipeline can trained end-to-end using the MRpro framework, allowing to learn to\n",
    "estimate spatially adaptive regularization parameter maps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### The method\n",
    "In the TV-example, (see <project:tv_minimization_reconstruction_pdhg.ipynb>), we have seen how to employ the primal\n",
    "dual hybrid gradient (PDHG) method # [[Chambolle \\& Pock, JMIV 2011](https://doi.org/10.1007%2Fs10851-010-0251-1)]\n",
    "to solve the TV-minimization problem. There, for data acquired according to the usual model\n",
    "\n",
    "$ y = Ax_{\\mathrm{true}} + n, $\n",
    "\n",
    "where $A$ contains the Fourier transform and the coil sensitivity maps operator, etc, and $n$ is complex-valued\n",
    "Gaussian noise, the TV-minimization problem was given as\n",
    "\n",
    "$\\mathcal{F}_{\\lambda}(x) = \\frac{1}{2}||Ax - y||_2^2 + \\lambda \\| \\nabla x \\|_1, \\quad \\quad \\quad (1)$\n",
    "\n",
    "where $\\nabla$ is the discretized gradient operator and $\\lambda>0$ globally dictates the strength of the\n",
    "regularization. Clearly, having one global regularization parameter $\\lambda$ for the entire image is\n",
    "not optimal, as the image content can vary significantly across the image. Therefore, in this example,\n",
    "we aim to learn spatially adaptive regularization parameter maps $\\Lambda$ from the input image to improve\n",
    "our TV-reconstruction. I.e., we are interested in estimating spatially adaptive regularization parameter maps by\n",
    "\n",
    "$\\Lambda_{\\theta}:=u_{\\theta}(x_0)$\n",
    "\n",
    "with a convolutional neural network $u_{\\theta}$ with trainable parameters $\\theta$, and then to consider the problem\n",
    "\n",
    "$\\mathcal{F}_{\\Lambda_{\\theta}}(x) = \\frac{1}{2}||Ax - y||_2^2 +  \\| \\Lambda_{\\theta} \\nabla x \\|_1, \\quad \\quad (2)$\n",
    "\n",
    "where $\\Lambda$ is point-wise strictly positive and locally regularizes the TV-minimization problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### The neural network\n",
    "In this simple example, we use a simple convolutional neural network to estimate the regularization parameter maps.\n",
    "Obviously, more complex architectures can be employed as well. For example, in the work in\n",
    "[[Kofler et al, SIIMS 2023](https://epubs.siam.org/doi/abs/10.1137/23M1552486)],\n",
    "a U-Net [[Ronneberger et al, MICCAI 2015](https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28)] was used.\n",
    "The network used here corresponds to a simple block of convolutional layers with leaky ReLU activations and a\n",
    "final softplus activation to ensure # that the regularization parameter maps are strictly positive.\n",
    "The network is defined in the following.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "\n",
    "\n",
    "class ParameterMapNetwork2D(nn.Module):\n",
    "    r\"\"\"A simple network for estimating regularization parameter maps for TV-reconstruction.\"\"\"\n",
    "\n",
    "    def __init__(self, n_filters: int = 16) -> None:\n",
    "        r\"\"\"Initialize Adaptive TV Network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_filters\n",
    "            number of filters to be applied in the convolutional layers of the network.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn_block = nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=2, out_channels=n_filters, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(in_channels=n_filters, out_channels=n_filters, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(in_channels=n_filters, out_channels=n_filters, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(in_channels=n_filters, out_channels=1, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "        self.t = 0.1\n",
    "\n",
    "    def forward(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        r\"\"\"Apply the network to estimate regularization parameter maps.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image\n",
    "            the image from which the regularization parameter maps should be estimated.\n",
    "\n",
    "        \"\"\"\n",
    "        regularization_parameter_map = self.cnn_block(image)\n",
    "\n",
    "        # stack the parameter map channel dimension to share the regularization\n",
    "        # between the x- and y-direction of the image gradients\n",
    "        regularization_parameter_map = torch.concat(2 * [regularization_parameter_map], dim=1)\n",
    "\n",
    "        # apply softplus to enforce strict positvity and scale by hand-crafted parameter\n",
    "        regularization_parameter_map = self.t * torch.nn.functional.softplus(regularization_parameter_map)\n",
    "        return regularization_parameter_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### The unrolled PDHG algorithm network\n",
    "We now construct the network that solves the TV-minimization problem with spatially adaptive regularization\n",
    "parameter maps by unrolling a finite number of iteration of PDHG.\n",
    "The network is defined in the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "```{note}\n",
    "To fully understand the mechanics of the network, we recommend to have a look at the TV-example in\n",
    "<project:tv_minimization_reconstruction_pdhg.ipynb>.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "However, put in simple words, the network takes the initial image, estimates the regularization\n",
    "parameter maps, and then sets up the # TV-problem within the \"forward\" of the network. The network\n",
    "then approximately solves the TV-problem using the PDHG algorithm # and returns the reconstructed image.\n",
    "\n",
    "import mrpro\n",
    "from mrpro.operators.LinearOperator import LinearOperator\n",
    "\n",
    "\n",
    "class AdaptiveTVNetwork2D(nn.Module):\n",
    "    r\"\"\"Unrolled primal dual hybrid gradient with spatially adaptive regularization parameter maps for TV.\n",
    "\n",
    "    Solves the minimization problem\n",
    "\n",
    "        :math:`\\min_x \\frac{1}{2}\\| Ax - y\\|_2^2 + \\| \\Lambda_{\\theta} \\nabla x\\|_1`,\n",
    "    where :math:`A` is the forward linear operator, :math:`\\nabla` is the gradient operator,\n",
    "    and :math:`\\Lambda_{\\theta}` is a strictly positive regularization parameter map that is estimated from\n",
    "    an input image with a network :math:`u_{\\theta}` with trainable parameters :math:`\\theta`.\n",
    "\n",
    "    N.B. The entire network sticks to the convention of MRpro, i.e. we work with images and k-space data\n",
    "    of shape (other*, coils, z, y, x). However, because here showcase the method for 2D problems,\n",
    "    some processing steps are necessary within the forward method. In particular, we restrict this example,\n",
    "    to be used with z=1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        fourier_operator: LinearOperator,\n",
    "        gradient_operator: LinearOperator,\n",
    "        lambda_map_network: torch.nn.Module,\n",
    "        n_iterations: int = 128,\n",
    "    ):\n",
    "        r\"\"\"Initialize Adaptive TV Network.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        fourier_operator\n",
    "            fourier_operator of the problem :math: `y=Ax + e` with :math:`A:=FS`,\n",
    "            where :math:`F` is the Fourier operator and :math:`S` is the sensitivity operator.\n",
    "        gradient_operator\n",
    "           the gradient operator to be used in the :math: `\\ell_1`-norm of the TV-problem.\n",
    "        lambda_map_network\n",
    "            a network that predicts a regularization parameter map from the input image.\n",
    "        n_iterations\n",
    "            number of iterations for the unrolled primal dual hybrid gradient (PDHG) algorithm.\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.fourier_operator = fourier_operator\n",
    "        self.gradient_operator = gradient_operator\n",
    "        self.lambda_map_network = lambda_map_network\n",
    "        self.n_iterations = n_iterations\n",
    "        self.g = mrpro.operators.functionals.ZeroFunctional()\n",
    "\n",
    "        # the operator norm of the stacked operator K = [fourier, gradient]^T;\n",
    "        # can be explicitly calculated\n",
    "        # self.register_buffer('operator_norm_K', torch.tensor([3.0]))\n",
    "        self.operator_norm_K = 3.0\n",
    "\n",
    "    def estimate_lambda_map(self, image: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Estimate regularization parameter map from image.\"\"\"\n",
    "        # squeeze the dimensions that are one. In particular, the initial image\n",
    "        # is a coil-combined image (i.e. coils=1) and because, we only consider 2D problems here,\n",
    "        # z can be assumed to be always 1.\n",
    "        # (other*, coils, z, y, x) -> (other*, y, x)\n",
    "        input_image = image.squeeze(-3).squeeze(-3)\n",
    "        input_image = rearrange(torch.view_as_real(input_image), 'other y x ch -> other ch y x')\n",
    "        regularization_parameter_map = self.lambda_map_network(input_image).unsqueeze(-3).unsqueeze(-3)\n",
    "        return regularization_parameter_map\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        initial_image: torch.Tensor,\n",
    "        csm: torch.Tensor,\n",
    "        kdata: torch.Tensor,\n",
    "        regularization_parameter: torch.Tensor | None = None,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Reconstruct image using an unrolled PDHG algorithm.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        initial_image\n",
    "            initial guess of the solution of the TV problem.\n",
    "        csm\n",
    "            coil sensitivity map tensor of the considered problem.\n",
    "        kdata\n",
    "            k-space data tensor of the considered problem.\n",
    "        regularization_parameter\n",
    "            regularization parameter to be used in the TV-functional. If set to None,\n",
    "            it is estimated by the lambda_map_network.\n",
    "            (can also be a single scalar)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            Image reconstructed by the TV-minimization algorithm.\n",
    "        \"\"\"\n",
    "        # if no regularization parameter map is provided, compute it with the network\n",
    "        if regularization_parameter is None:\n",
    "            regularization_parameter = self.estimate_lambda_map(initial_image)\n",
    "\n",
    "        # set up the problem K = [A, \\nabla]^T, f=f1+f2, g=0\n",
    "        csm_operator = mrpro.operators.SensitivityOp(csm).to(initial_image.device)\n",
    "        forward_model = self.fourier_operator @ csm_operator\n",
    "        self.K_op = mrpro.operators.LinearOperatorMatrix(((forward_model,), (self.gradient_operator,)))\n",
    "        f_1 = 0.5 * mrpro.operators.functionals.L2NormSquared(target=kdata, divide_by_n=False)\n",
    "        f_2 = mrpro.operators.functionals.L1NormViewAsReal(weight=regularization_parameter, divide_by_n=False)\n",
    "        f = mrpro.operators.ProximableFunctionalSeparableSum(f_1, f_2)\n",
    "\n",
    "        primal_stepsize = dual_stepsize = 0.95 * 1.0 / self.operator_norm_K\n",
    "\n",
    "        (solution,) = mrpro.algorithms.optimizers.pdhg(\n",
    "            f=f,\n",
    "            g=self.g,\n",
    "            operator=self.K_op,\n",
    "            initial_values=(initial_image,),\n",
    "            max_iterations=self.n_iterations,\n",
    "            primal_stepsize=primal_stepsize,\n",
    "            dual_stepsize=dual_stepsize,\n",
    "            tolerance=0.0,\n",
    "        )\n",
    "        return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## %% [markdown]\n",
    "# ### Creating training data\n",
    "# In the following, we create some training data for the network. We use some images borrowed from the\n",
    "# BrainWeb dataset [[Aubert-Broche et al, IEEE TMI 2006](https://ieeexplore.ieee.org/abstract/document/1717639),\n",
    "# which is a simulated MRI dataset and for which MRpro provides a simple interface to load the data, see ...\n",
    "# For simplicity, we here use a set of XXX images that were generated by simulating the contrast using the\n",
    "# inversion recovery signl model in ...\n",
    "# First, we start by defining some auxiliary functions that we will need for retrospectively simulating undersampled\n",
    "# and noiy k-space data.\n",
    "def normal_pdf(length: int, sensitivity: float) -> torch.Tensor:\n",
    "    \"\"\"Return the normal probability density function.\"\"\"\n",
    "    return torch.exp(-sensitivity * (torch.arange(length) - length / 2) ** 2)\n",
    "\n",
    "\n",
    "def choose_kspace_lines(n_samples: int, acceleration_factor: float, sample_n: int = 10) -> torch.Tensor:\n",
    "    \"\"\"Choose k-space lines according to Gaussian.\"\"\"\n",
    "    n_to_keep = int(n_samples // acceleration_factor)\n",
    "    pdf_x = normal_pdf(n_samples, 0.5 / (n_samples / 10.0) ** 2)\n",
    "    lmda = n_samples / (2.0 * acceleration_factor)\n",
    "    # add uniform distribution\n",
    "    pdf_x += lmda * 1.0 / n_samples\n",
    "    if sample_n:\n",
    "        pdf_x[n_samples // 2 - sample_n // 2 : n_samples // 2 + sample_n // 2] = 0\n",
    "        pdf_x /= torch.sum(pdf_x)\n",
    "        n_to_keep -= sample_n\n",
    "    indices = pdf_x.multinomial(num_samples=n_samples, replacement=False)\n",
    "    k1_idx = torch.arange(0, n_samples)[indices[:n_to_keep]]\n",
    "    if sample_n:\n",
    "        center_indices = torch.arange(n_samples // 2 - sample_n // 2, n_samples // 2 + sample_n // 2)\n",
    "        k1_idx = torch.cat([k1_idx, center_indices], dim=-1)\n",
    "    return torch.sort(k1_idx)[0]\n",
    "\n",
    "\n",
    "from collections.abc import Sequence\n",
    "\n",
    "\n",
    "def add_gaussian_noise(kdata: torch.Tensor, dim: Sequence[int] | None, noise_variance: float) -> torch.Tensor:\n",
    "    \"\"\"Corrupt given k-space data with additive Gaussian noise.\"\"\"\n",
    "    dim = tuple(dim) if dim is not None else dim\n",
    "    mu, std = kdata.mean(dim=dim, keepdim=True), kdata.std(dim=dim, keepdim=True)\n",
    "    kdata = (kdata - mu) / std\n",
    "    kdata = kdata + noise_variance * torch.randn_like(kdata)\n",
    "    kdata = kdata * std + mu\n",
    "    return kdata\n",
    "\n",
    "\n",
    "class BrainWeb2D(torch.utils.data.Dataset):\n",
    "    r\"\"\"BrainWeb dataset for 2D problems.\"\"\"\n",
    "\n",
    "    def __init__(self, images: torch.Tensor) -> None:\n",
    "        \"\"\"Parameters\n",
    "\n",
    "        ----------\n",
    "        images\n",
    "            images to be used in the dataset.\n",
    "        \"\"\"\n",
    "        # unsqueeze (N,ny,nx) images to match the MRpro convention (others, coils, z, y, x)\n",
    "        self.images = images.unsqueeze(-3).unsqueeze(-3)\n",
    "        self.ny, self.nx = self.images.shape[-2:]\n",
    "        self.n_k1, self.n_k0 = self.ny, self.nx\n",
    "        self.im_shape = mrpro.data.SpatialDimension(z=1, y=self.ny, x=self.nx)\n",
    "        self.k_shape = mrpro.data.SpatialDimension(z=1, y=self.n_k1, x=self.n_k0)\n",
    "\n",
    "    def prepare_data(\n",
    "        self, image: torch.Tensor, n_coils: int, acceleration_factor: float, noise_variance: float\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, LinearOperator]:\n",
    "        \"\"\"Prepare data for training by simulating k-space data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        image : torch.Tensor\n",
    "            Input image to be used for simulation.\n",
    "        n_coils : int\n",
    "            Number of coils for the simulation.\n",
    "        acceleration_factor : float\n",
    "            Acceleration factor for undersampling.\n",
    "        noise_variance : float\n",
    "            Variance of the Gaussian noise to be added.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple\n",
    "            A tuple containing k-space data, coil sensitivity maps, adjoint reconstruction,\n",
    "            pseudo-inverse solution, original image, and the Fourier operator.\n",
    "        \"\"\"\n",
    "        # randomly choose trajectories to define the fourier operator\n",
    "        k1_idx = choose_kspace_lines(self.n_k1, acceleration_factor=acceleration_factor)\n",
    "        traj = mrpro.data.traj_calculators.KTrajectoryCartesian()(\n",
    "            n_k0=self.n_k0,\n",
    "            k0_center=self.n_k0 // 2,\n",
    "            k1_idx=k1_idx[:, None],\n",
    "            k1_center=self.n_k1 // 2,\n",
    "            k2_idx=torch.tensor(0),\n",
    "            k2_center=0,\n",
    "        )\n",
    "\n",
    "        fourier_operator = mrpro.operators.FourierOp(\n",
    "            traj=traj,\n",
    "            recon_matrix=self.im_shape,\n",
    "            encoding_matrix=self.k_shape,\n",
    "        )\n",
    "\n",
    "        # generate simualated coil sensitivity maps\n",
    "        from mrpro.phantoms.coils import birdcage_2d\n",
    "\n",
    "        csm = birdcage_2d(n_coils, self.im_shape, relative_radius=0.8)\n",
    "        csm_operator = mrpro.operators.SensitivityOp(csm)\n",
    "\n",
    "        forward_operator = fourier_operator @ csm_operator\n",
    "\n",
    "        (kdata,) = forward_operator(image)\n",
    "        kdata = add_gaussian_noise(kdata, dim=(-2, -1), noise_variance=noise_variance)\n",
    "        (adjoint_recon,) = forward_operator.H(kdata)\n",
    "\n",
    "        pseudo_inverse_solution = mrpro.algorithms.optimizers.cg(\n",
    "            forward_operator.gram, right_hand_side=adjoint_recon, initial_value=adjoint_recon, max_iterations=16\n",
    "        )\n",
    "\n",
    "        return kdata, csm, adjoint_recon, pseudo_inverse_solution, image, fourier_operator\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"Return the number of images in the dataset.\"\"\"\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        \"\"\"Return the image and retrospectively generate k-space data.\"\"\"\n",
    "        image = self.images[idx]\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.load('/echo/kofler01/brainweb_data/processed/brainweb_data.pt')\n",
    "images = torch.view_as_complex(\n",
    "    rearrange(\n",
    "        torch.nn.functional.max_pool2d(\n",
    "            rearrange(torch.view_as_real(images), 'b y x ri -> b ri y x'), kernel_size=2, stride=2\n",
    "        ),\n",
    "        'b ri y x -> b y x ri',\n",
    "        ri=2,\n",
    "    ),\n",
    ")\n",
    "images = torch.rot90(images, k=-1, dims=(-2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 120\n",
    "images_train = images[:n_train, ...]\n",
    "images_validation = images[n_train:, ...]\n",
    "\n",
    "dataset_train = BrainWeb2D(images=images_train)\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, shuffle=True)\n",
    "\n",
    "dataset_validation = BrainWeb2D(images=images_validation)\n",
    "dataloader_validation = torch.utils.data.DataLoader(dataset_train, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Let's have a look at an example of the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show plotting details"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "def show_images(*images: torch.Tensor, titles: list[str] | None = None, cmap: str = 'grey') -> None:\n",
    "    \"\"\"Plot images.\"\"\"\n",
    "    n_images = len(images)\n",
    "    _, axes = plt.subplots(1, n_images, squeeze=False, figsize=(n_images * 3, 3))\n",
    "    for i in range(n_images):\n",
    "        axes[0][i].imshow(images[i].rot90(k=-1, dims=(-2, -1)), cmap=cmap)\n",
    "        axes[0][i].axis('off')\n",
    "        if titles:\n",
    "            axes[0][i].set_title(titles[i])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "_, image = next(enumerate(dataloader_validation))\n",
    "\n",
    "n_coils = 8\n",
    "noise_variance = 0.05\n",
    "acceleration_factor = 4\n",
    "kdata, csm, adjoint_recon, pseudo_inverse_solution, image, fourier_operator = dataset_validation.prepare_data(\n",
    "    image, n_coils=n_coils, acceleration_factor=acceleration_factor, noise_variance=noise_variance\n",
    ")\n",
    "\n",
    "show_images(\n",
    "    adjoint_recon.abs().squeeze(),\n",
    "    pseudo_inverse_solution.abs().squeeze(),\n",
    "    image.abs().squeeze(),\n",
    "    titles=['adjoint', 'pseudo-inverse', 'target'],\n",
    ")\n",
    "\n",
    "# %%[markdown]\n",
    "# We now construct the unrolled PDHG network. Let us also first have a look at what the current estimates\n",
    "# of the regularization parameter maps look like prior to training.\n",
    "\n",
    "# construct gradient operator; also use the Rearrange operator to bring\n",
    "finite_differences_operator = mrpro.operators.FiniteDifferenceOp(dim=(-2, -1), mode='forward')\n",
    "gradient_operator = mrpro.operators.RearrangeOp('grad batch ... -> batch grad ... ') @ finite_differences_operator\n",
    "lambda_map_network = ParameterMapNetwork2D(n_filters=16)\n",
    "n_iterations = 16\n",
    "adaptive_tv_network = AdaptiveTVNetwork2D(\n",
    "    fourier_operator=fourier_operator,\n",
    "    gradient_operator=gradient_operator,\n",
    "    lambda_map_network=lambda_map_network,\n",
    "    n_iterations=n_iterations,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    regularization_parameter_map = adaptive_tv_network.estimate_lambda_map(pseudo_inverse_solution)\n",
    "\n",
    "    regularization_parameter_scalar = torch.tensor(0.01)\n",
    "\n",
    "    pdhg_recon_scalar = adaptive_tv_network(pseudo_inverse_solution, csm, kdata, regularization_parameter_scalar)\n",
    "\n",
    "show_images(\n",
    "    adjoint_recon.abs().squeeze(),\n",
    "    pseudo_inverse_solution.abs().squeeze(),\n",
    "    pdhg_recon_scalar.abs().squeeze(),\n",
    "    image.abs().squeeze(),\n",
    "    titles=['adjoint', 'pseudo-inverse', 'pdhg (scalar reg)', 'target'],\n",
    ")\n",
    "show_images(\n",
    "    regularization_parameter_map[0, 0].abs().squeeze(), titles=['spatial regularization parameter map'], cmap='inferno'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(adaptive_tv_network.parameters(), lr=learning_rate)\n",
    "# loss_function = mrpro.operators.functionals.MSE(image) # todo\n",
    "loss_function = nn.MSELoss()\n",
    "n_epochs = 36\n",
    "\n",
    "loss_vals = []\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    adaptive_tv_network = adaptive_tv_network.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(n_epochs):\n",
    "    for _, image in enumerate(dataloader_train):\n",
    "        print(_)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        noise_variance = 0.05\n",
    "        acceleration_factor = 4\n",
    "        kdata, csm, adjoint_recon, pseudo_inverse_solution, image, fourier_operator = dataset_train.prepare_data(\n",
    "            image, n_coils=n_coils, acceleration_factor=acceleration_factor, noise_variance=noise_variance\n",
    "        )\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            pseudo_inverse_solution = pseudo_inverse_solution.cuda()\n",
    "            csm = csm.cuda()\n",
    "            kdata = kdata.cuda()\n",
    "            image = image.cuda()\n",
    "            fourier_operator = fourier_operator.cuda()\n",
    "\n",
    "        adaptive_tv_network.fourier_operator = fourier_operator\n",
    "        pdhg_recon = adaptive_tv_network(pseudo_inverse_solution, csm, kdata)\n",
    "\n",
    "        loss = loss_function(torch.view_as_real(pdhg_recon), torch.view_as_real(image))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "        loss_vals.append(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Well done, we have successfully reconstructed an image with spatially adaptive regularization parameter\n",
    "maps for TV.\n",
    "\n",
    "### Next steps\n",
    "As previously mentioned, you can change network architecture. Do deeper/wider networks give more accurate results?\n",
    "Further, you can play around with the number of iterations used for unrolling PDHG at training time. How does this\n",
    "number of # iterations the obtained lambda maps and the final reconstruction?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "mystnb,tags,-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
