{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PTB-MR/mrpro/blob/main/examples/notebooks/qmri_cardiac_fingerprinting.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "if not importlib.util.find_spec('mrpro'):\n",
    "    %pip install mrpro[notebooks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "# Cardiac MRF reconstructions\n",
    "\n",
    "This notebook provides the image reconstruction and parameter estimation methods required to reconstruct cardiac MR\n",
    "Fingerprinting (cMRF) data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    "# Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# In this notebook the cardiac MR Fingerprinting (cMRF) data acquired at one scanner and the corresponding spin-echo\n",
    "# reference sequence are reconstructed and $T_1$ and $T_2$ maps are estimated. This example is based on the same\n",
    "# data as for one of the scanners in the scanner comparison example in [SCHUE2024].  Average $T_1$ and $T_2$ are\n",
    "# calculated in circular ROIs for different tissue types represented in the phantom.\n",
    "\n",
    "\n",
    "# For the reconstruction of the acquired data the cMRF signal model is used. This model simulates a cardiac MR\n",
    "# fingerprinting sequence as described in [HAMI2017]_ using the extended phase graph\n",
    "# (`~mrpro.operators.models.EPG`) formalism.\n",
    "\n",
    "# It is a four-fold repetition of\n",
    "\n",
    "#             Block 0                   Block 1                   Block 2                     Block 3\n",
    "#    R-peak                   R-peak                    R-peak                    R-peak                    R-peak\n",
    "# ---|-------------------------|-------------------------|-------------------------|-------------------------|-----\n",
    "\n",
    "#         [INV TI=30ms][ACQ]                     [ACQ]     [T2-prep TE=50ms][ACQ]    [T2-prep TE=100ms][ACQ]\n",
    "\n",
    "# In order not to reconstruct all acquired images, the acquired data is split into windows of 20 acquisitions. The\n",
    "# windows have an overap of 10 acquisitins among each other.  As a result the acquired data is averaged over these\n",
    "# windows, so that less images have to be reconstructed.\n",
    "\n",
    "# We carry out dictionary matching to estimate the quantitative parameters from a series of qualitative images. For\n",
    "# this we employ `~mrpro.operators.DictionaryMatchOp`. It performs absolute normalized dot product matching between\n",
    "# a dictionary of signals, i.e. find the entry :math:`d^*` in the dictionary maximizing\n",
    "# :math:`\\left|\\frac{d}{\\|d\\|} \\cdot \\frac{y}{\\|y\\|}\\right|` and returns the associated signal model parameters\n",
    "# :math:`x` generating the matching signal :math:`d^*=d(x)`.\n",
    "\n",
    "# At initialization, the cMRF signal model from before needs to be provided. In addition to the extended phase graph\n",
    "# formalism the simulated signal is averaged over 45 acquisition windows consisting of 20 acquisitions with an overlap\n",
    "# of ten acquisitions. Then parameters like $m_0$, $T_1$ and $T_2$ are provided as entries for the dictionary and the\n",
    "# cMRF signal model from before is applied on them. Given the reconstructed images from above, the tuple of\n",
    "# ($m_0$, $T_1$, $T_2$)-values in the dictionary that result in  a signal with the highest dot-product similarity\n",
    "# will be returned.\n",
    "\n",
    "# References\n",
    "# ----------\n",
    "# .. [SCHUE2024] Schuenke, P. et al. (2024) Open-Source Cardiac MR Fingerprinting\n",
    "# .. [HAMI2017] Hamilton, J. I. et al. (2017) MR fingerprinting for rapid quantification of myocardial T1, T2, and\n",
    "#         proton spin density. Magn. Reson. Med. 77 http://doi.wiley.com/10.1002/mrm.26668"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    "In this example, we are going to:\n",
    "- Download data\n",
    "- Define image reconstruction and parameter estimation methods for cMRF and reference sequences\n",
    "- Run through all datasets and calculate $T_1$ and $T_2$ maps\n",
    "- Visualize and evaluate results\n",
    "- Assertion of cMRF results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show download details"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Download data from zenodo\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import zenodo_get\n",
    "\n",
    "dataset = '14617082'  # FIXME: Change to real dataset!\n",
    "\n",
    "tmp = tempfile.TemporaryDirectory()  # RAII, automatically cleaned up\n",
    "data_folder = Path(tmp.name)\n",
    "zenodo_get.zenodo_get([dataset, '-r', 5, '-o', data_folder])  # r: retries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mrpro\n",
    "\n",
    "kdata = mrpro.data.KData.from_file(data_folder / 'cMRF.h5', mrpro.data.traj_calculators.KTrajectoryIsmrmrd())\n",
    "avg_recon = mrpro.algorithms.reconstruction.DirectReconstruction(kdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We want to perform a sliding window reconstruction respecting the block structure of the acquisition.\n",
    "We construct a split index that splits the data into windows of 10 acquisitions with an overlap of 5 acquisitions.\n",
    "\n",
    "import torch\n",
    "\n",
    "n_acq_per_image = 10\n",
    "n_overlap = 5\n",
    "n_acq_per_block = 47\n",
    "n_blocks = 15\n",
    "\n",
    "idx_in_block = torch.arange(n_acq_per_block).unfold(0, n_acq_per_image, n_acq_per_image - n_overlap)\n",
    "split_indices = (n_acq_per_block * torch.arange(n_blocks)[:, None, None] + idx_in_block).flatten(end_dim=1)\n",
    "kdata_split = kdata[..., split_indices, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "We can now perform the reconstruction for each window.\n",
    "avg_recon = mrpro.algorithms.reconstruction.DirectReconstruction(kdata)\n",
    "recon = mrpro.algorithms.reconstruction.DirectReconstruction(kdata_split, csm=avg_recon.csm)\n",
    "img = recon(kdata_split).data[:, 0, :, :]\n",
    "\n",
    "\n",
    "Dictionary settings\n",
    "t1_keys = torch.arange(0.05, 5, 0.01)[:, None]\n",
    "t2_keys = torch.arange(0.006, 0.5, 0.002)[None, :]\n",
    "m0_keys = torch.tensor(1.0)\n",
    "\n",
    "model = mrpro.operators.AveragingOp(dim=0, idx=split_indices) @ mrpro.operators.models.CardiacFingerprinting(\n",
    "    kdata.header.acq_info.acquisition_time_stamp.squeeze(), echo_time=0.00155\n",
    ")\n",
    "dictionary = mrpro.operators.DictionaryMatchOp(model, index_of_scaling_parameter=0).append(m0_keys, t1_keys, t2_keys)\n",
    "m0_match, t1_match, t2_match = dictionary(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show statistics helper functions"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def image_statistics(idat: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Calculate mean value and standard deviation in the ROIs.\"\"\"\n",
    "    mask = np.squeeze(np.load(data_folder / 'mask.npy'))\n",
    "    n_tubes = 9\n",
    "    mean = torch.cat([torch.mean(idat[mask == idx]) for idx in range(1, n_tubes + 1)])\n",
    "    std_deviation = torch.cat([torch.std(idat[mask == idx]) for idx in range(1, n_tubes + 1)])\n",
    "    return mean, std_deviation\n",
    "\n",
    "\n",
    "def r_squared(true: torch.Tensor, predicted: torch.Tensor) -> float:\n",
    "    \"\"\"Calculate the coefficient of determination (R-squared).\"\"\"\n",
    "    total = ((true - true.mean()) ** 2).sum()\n",
    "    residual = (true - predicted).sum() ** 2\n",
    "    r2 = 1 - residual / total\n",
    "    return r2.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Visualize and evaluate results\n",
    "Now we visualize and compare all the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show plotting code"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from cmap import Colormap\n",
    "\n",
    "\n",
    "def show_image(t1: torch.Tensor, t2: torch.Tensor) -> None:\n",
    "    \"\"\"Show the cMRF $T_1$ and $T_2$ maps.\"\"\"\n",
    "    cmap_t1 = Colormap('lipari')\n",
    "    cmap_t2 = Colormap('navia')\n",
    "    fig, ax = plt.subplots(2, 1)\n",
    "\n",
    "    im = ax[0].imshow(t1.numpy(force=True), vmin=0, vmax=2, cmap=cmap_t1.to_mpl())\n",
    "    ax[0].set_title('cMRF T1 (s)')\n",
    "    ax[0].set_axis_off()\n",
    "    plt.colorbar(im)\n",
    "\n",
    "    im = ax[1].imshow(t2.numpy(force=True), vmin=0, vmax=0.2, cmap=cmap_t2.to_mpl())\n",
    "    ax[1].set_title('cMRF T2 (s)')\n",
    "    ax[1].set_axis_off()\n",
    "    plt.colorbar(im)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Visualize and evaluate results\n",
    "We can plot the cMRF $T_1$ and $T_2$ maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "show_image(t1_match, t2_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We can also plot the statistics of the cMRF $T_1$ and $T_2$ maps and compare them to pre-calculated reference values,\n",
    "obtained from a separate reference scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show plotting code"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Pre-calculated $T_1$ and $T_2$ spin-echo reference values for the nine tubes\n",
    "t1_mean_ref = torch.tensor([1.022, 0.336, 0.287, 1.379, 0.430, 0.430, 1.755, 0.557, 0.580])\n",
    "t1_std_ref = torch.tensor([0.012, 0.005, 0.004, 0.024, 0.007, 0.003, 0.028, 0.006, 0.003])\n",
    "t2_mean_ref = torch.tensor([0.030, 0.033, 0.113, 0.037, 0.032, 0.123, 0.185, 0.032, 0.120])\n",
    "t2_std_ref = torch.tensor([0.009, 0.001, 0.003, 0.001, 0.001, 0.002, 0.003, 0.001, 0.004])\n",
    "\n",
    "\n",
    "t1_mean_cmrf, t1_std_cmrf = image_statistics(t1_match)\n",
    "t2_mean_cmrf, t2_std_cmrf = image_statistics(t2_match)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 7))\n",
    "ax[0].errorbar(t1_mean_ref, t1_mean_cmrf, t1_std_cmrf, t1_std_ref, fmt='o', color='teal')\n",
    "ax[0].plot([0, 2000], [0, 2000], color='darkorange')\n",
    "ax[0].text(\n",
    "    200,\n",
    "    1800,\n",
    "    rf'$R^2$ = {r_squared(t1_mean_ref, t1_mean_cmrf):.4f}',\n",
    "    fontsize=12,\n",
    "    verticalalignment='top',\n",
    "    horizontalalignment='left',\n",
    "    bbox={'facecolor': 'white', 'alpha': 0.5},\n",
    ")\n",
    "ax[0].set_xlabel('T1 - Reference (s)', fontsize=14)\n",
    "ax[0].set_ylabel('T1 - cMRF (s)', fontsize=14)\n",
    "ax[0].grid()\n",
    "ax[0].set_aspect('equal', adjustable='box')\n",
    "\n",
    "ax[1].errorbar(t2_mean_ref, t2_mean_cmrf, t2_std_cmrf, t2_std_ref, fmt='o', color='teal')\n",
    "ax[1].plot([0, 200], [0, 200], color='darkorange')\n",
    "ax[1].text(\n",
    "    20,\n",
    "    180,\n",
    "    rf'$R^2$ = {r_squared(t2_mean_ref, t2_mean_cmrf):.4f}',\n",
    "    fontsize=12,\n",
    "    verticalalignment='top',\n",
    "    horizontalalignment='left',\n",
    "    bbox={'facecolor': 'white', 'alpha': 0.5},\n",
    ")\n",
    "ax[1].set_xlabel('T2 - Reference (s)', fontsize=14)\n",
    "ax[1].set_ylabel('T2 - cMRF (s)', fontsize=14)\n",
    "ax[1].grid()\n",
    "ax[1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Assertion verifies if cMRF results match the pre-calculated reference values\n",
    "torch.testing.assert_close(t1_mean_ref, t1_mean_cmrf, atol=0, rtol=0.15)\n",
    "torch.testing.assert_close(t2_mean_ref, t2_mean_cmrf, atol=0, rtol=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "mystnb,tags,-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
