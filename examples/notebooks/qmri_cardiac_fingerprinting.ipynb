{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PTB-MR/mrpro/blob/main/examples/notebooks/qmri_cardiac_fingerprinting.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "if not importlib.util.find_spec('mrpro'):\n",
    "    %pip install mrpro[notebooks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Cardiac MR Fingerprinting\n",
    "\n",
    "This notebook provides the image reconstruction and parameter estimation methods required to reconstruct cardiac MR\n",
    "Fingerprinting (cMRF) data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    "## Overview\n",
    "In this notebook, data from a cardiac MR Fingerprinting (cMRF) experiment is reconstructed and\n",
    "$T_1$ and $T_2$ maps are estimated. This example uses data from [Schuenke et al., 2024](in submission) of a phantom\n",
    "consisting of 9 tubes. Average $T_1$ and $T_2$ are calculated for each tube.\n",
    "\n",
    "The fingerprinting sequence, as described by [Hamilton et al., 2017](https://doi.org/10.1002/mrm.26668) and\n",
    "[Schuenke et al., 2024](in submission), consists of three repetitions of the following 5-block structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Block 0          Block 1          Block 2          Block 3          Block 4\n",
    "# R-peak           R-peak           R-peak           R-peak           R-peak\n",
    "# |----------------|----------------|----------------|----------------|----------------\n",
    "# [INV][ACQ]           [ACQ]       [T2-prep][ACQ]      [T2-prep][ACQ]   [T2-prep][ACQ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "where [INV] represents an inversion pulse, [ACQ] an acquisition, and [T2-prep] a T2-preparation pulse.\n",
    "\n",
    "We carry out dictionary matching to estimate $T_1$ and $T_2$ from a series of reconstructed qualitative images using\n",
    "normalized dot product matching between the images and a dictionary of pre-calculated signals. Pixelwise, we find the\n",
    "entry $d^*$ in the dictionary maximizing $\\left|\\frac{d}{\\|d\\|} \\cdot \\frac{y}{\\|y\\|}\\right|$ for the reconstructed\n",
    "signal $y$. The parameters $x$ generating the matching dictionary entry $d^*=d(x)$ are then used to estimate\n",
    "the quantitative parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "\n",
    "In the following, we are going to:\n",
    "- Download data from zenodo.\n",
    "- Reconstruct the qualitative images using a sliding window reconstruction.\n",
    "- Perform dictionary matching to estimate the quantitative parameters from the qualitative images.\n",
    "- Visualize and evaluate results.\n",
    "- Check if the cMRF results match the reference values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "lines_to_next_cell": 2,
    "mystnb": {
     "code_prompt_show": "Show download details"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Download data from zenodo\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import zenodo_get\n",
    "\n",
    "tmp = tempfile.TemporaryDirectory()  # RAII, automatically cleaned up\n",
    "data_folder = Path(tmp.name)\n",
    "zenodo_get.download(record='15726937', retry_attempts=5, output_dir=data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Reconstruct qualitative images\n",
    "We first load the data from a downloaded ISMRMRD file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mrpro\n",
    "\n",
    "kdata = mrpro.data.KData.from_file(data_folder / 'cMRF.h5', mrpro.data.traj_calculators.KTrajectoryIsmrmrd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "We want to perform a sliding window reconstruction respecting the block structure of the acquisition.\n",
    "We construct a split index that splits the data into windows of 20 acquisitions with an overlap of 10 acquisitions.\n",
    "Here, we can make use of the indexing functionality of `~mrpro.data.KData` to split the data into windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "n_acq_per_image = 20\n",
    "n_overlap = 10\n",
    "n_acq_per_block = 47\n",
    "n_blocks = 15\n",
    "\n",
    "idx_in_block = torch.arange(n_acq_per_block).unfold(0, n_acq_per_image, n_acq_per_image - n_overlap)\n",
    "split_indices = (n_acq_per_block * torch.arange(n_blocks)[:, None, None] + idx_in_block).flatten(end_dim=1)\n",
    "kdata_split = kdata[..., split_indices, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "We can now perform the reconstruction for each window. We first perform an averaged reconstruction over all\n",
    "acquisitions to get a good estimate of the coil sensitivities before performing the windowed reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_recon = mrpro.algorithms.reconstruction.DirectReconstruction(kdata)\n",
    "recon = mrpro.algorithms.reconstruction.DirectReconstruction(kdata_split, csm=avg_recon.csm)\n",
    "img = recon(kdata_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Dictionary matching\n",
    "Next, we calculate the dictionary.\n",
    "First, we set up the `~mrpro.operators.models.CardiacFingerprinting` operator and an `~mrpro.operators.AveragingOp`\n",
    "operator. This `~mrpro.operators.AveragingOp` mimics the averaging performed by the sliding window reconstruction\n",
    "and applies it to the simulated signals generated by the `~mrpro.operators.models.CardiacFingerprinting` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mrpro.operators.AveragingOp(dim=0, idx=split_indices) @ mrpro.operators.models.CardiacFingerprinting(\n",
    "    kdata.header.acq_info.acquisition_time_stamp.squeeze(),\n",
    "    echo_time=0.001555,\n",
    "    repetition_time=0.01,\n",
    "    t2_prep_echo_times=(0.03, 0.05, 0.1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Next, we pass this signal model to the  `~mrpro.operators.DictionaryMatchOp` operator to create a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "dictionary = mrpro.operators.DictionaryMatchOp(model, index_of_scaling_parameter=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Next, we choose a suitable range of $T_1$ and $T_2$ values for the\n",
    "dictionary. We can keep $M_0$ constant at ``1.0``, as dictionary matching is invariant to a scaling factor.\n",
    "By adding these keys to the dictionary, the `~mrpro.operators.DictionaryMatchOp` operator will use the signal\n",
    "model to calculate the dictionary entries for the given $M_0$, $T_1$ and $T_2$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "lines_to_next_cell": 0,
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "t1_keys = torch.arange(0.05, 2, 0.01)[:, None]\n",
    "t2_keys = torch.arange(0.006, 0.2, 0.002)[None, :]\n",
    "m0_keys = torch.tensor(1.0)\n",
    "dictionary.append(m0_keys, t1_keys, t2_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "We can now perform the dictionary matching by passing the reconstructed image data to the\n",
    "`~mrpro.operators.DictionaryMatchOp` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "m0_match, t1_match, t2_match = dictionary(img.data[:, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Visualize and evaluate results\n",
    "Great! Now we can visualize and evaluate the results. We can plot the cMRF $T_1$ and $T_2$ maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show plotting code"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from cmap import Colormap\n",
    "\n",
    "\n",
    "def show_image(t1: torch.Tensor, t2: torch.Tensor) -> None:\n",
    "    \"\"\"Show the cMRF $T_1$ and $T_2$ maps.\"\"\"\n",
    "    fig, ax = plt.subplots(2, 1)\n",
    "\n",
    "    im = ax[0].imshow(t1.numpy(force=True), vmin=0, vmax=2, cmap=Colormap('lipari').to_mpl())\n",
    "    ax[0].set_title('cMRF T1 (s)')\n",
    "    ax[0].set_axis_off()\n",
    "    plt.colorbar(im)\n",
    "\n",
    "    im = ax[1].imshow(t2.numpy(force=True), vmin=0, vmax=0.2, cmap=Colormap('navia').to_mpl())\n",
    "    ax[1].set_title('cMRF T2 (s)')\n",
    "    ax[1].set_axis_off()\n",
    "    plt.colorbar(im)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(t1_match, t2_match)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "We can also plot the statistics of the cMRF $T_1$ and $T_2$ maps and compare them to pre-calculated reference values,\n",
    "obtained from a separate reference scan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show statistics helper functions"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def image_statistics(idat: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"Calculate mean value and standard deviation in the ROIs.\"\"\"\n",
    "    mask = np.squeeze(np.load(data_folder / 'mask.npy'))\n",
    "    n_tubes = 9\n",
    "    mean = torch.stack([torch.mean(idat[mask == idx]) for idx in range(1, n_tubes + 1)])\n",
    "    std_deviation = torch.stack([torch.std(idat[mask == idx]) for idx in range(1, n_tubes + 1)])\n",
    "    return mean, std_deviation\n",
    "\n",
    "\n",
    "def r_squared(true: torch.Tensor, predicted: torch.Tensor) -> float:\n",
    "    \"\"\"Calculate the coefficient of determination (R-squared).\"\"\"\n",
    "    total = ((true - true.mean()) ** 2).sum()\n",
    "    residual = ((true - predicted) ** 2).sum()\n",
    "    r2 = 1 - residual / total\n",
    "    return r2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show plotting code"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Loading of reference maps and time conversion from ms to s\n",
    "ref_t1_maps = torch.tensor(np.load(data_folder / 'ref_t1.npy')) / 1000\n",
    "ref_t2_maps = torch.tensor(np.load(data_folder / 'ref_t2.npy')) / 1000\n",
    "t1_mean_ref, t1_std_ref = image_statistics(ref_t1_maps)\n",
    "t2_mean_ref, t2_std_ref = image_statistics(ref_t2_maps)\n",
    "t1_mean_cmrf, t1_std_cmrf = image_statistics(t1_match)\n",
    "t2_mean_cmrf, t2_std_cmrf = image_statistics(t2_match)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 7))\n",
    "ax[0].errorbar(t1_mean_ref, t1_mean_cmrf, t1_std_cmrf, t1_std_ref, fmt='o', color='teal')\n",
    "ax[0].plot([0, 2.0], [0, 2.0], color='darkorange')\n",
    "ax[0].text(\n",
    "    0.2,\n",
    "    1.800,\n",
    "    rf'$R^2$ = {r_squared(t1_mean_ref, t1_mean_cmrf):.4f}',\n",
    "    fontsize=12,\n",
    "    verticalalignment='top',\n",
    "    horizontalalignment='left',\n",
    "    bbox={'facecolor': 'white', 'alpha': 0.5},\n",
    ")\n",
    "ax[0].set_xlabel('$T_1$ - Reference (s)', fontsize=14)\n",
    "ax[0].set_ylabel('$T_1$ - cMRF (s)', fontsize=14)\n",
    "ax[0].grid()\n",
    "ax[0].set_aspect('equal', adjustable='box')\n",
    "\n",
    "ax[1].errorbar(t2_mean_ref, t2_mean_cmrf, t2_std_cmrf, t2_std_ref, fmt='o', color='teal')\n",
    "ax[1].plot([0, 0.2], [0, 0.2], color='darkorange')\n",
    "ax[1].text(\n",
    "    0.02,\n",
    "    0.180,\n",
    "    rf'$R^2$ = {r_squared(t2_mean_ref, t2_mean_cmrf):.4f}',\n",
    "    fontsize=12,\n",
    "    verticalalignment='top',\n",
    "    horizontalalignment='left',\n",
    "    bbox={'facecolor': 'white', 'alpha': 0.5},\n",
    ")\n",
    "ax[1].set_xlabel('$T_2$ - Reference (s)', fontsize=14)\n",
    "ax[1].set_ylabel('$T_2$ - cMRF (s)', fontsize=14)\n",
    "ax[1].grid()\n",
    "ax[1].set_aspect('equal', adjustable='box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Assertion verifies if cMRF results match the pre-calculated reference values\n",
    "torch.testing.assert_close(t1_mean_ref, t1_mean_cmrf, atol=0, rtol=0.15)\n",
    "torch.testing.assert_close(t2_mean_ref, t2_mean_cmrf, atol=0, rtol=0.15)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "mystnb,tags,-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
