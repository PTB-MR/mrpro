{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/fzimmermann89/mr2/blob/main/examples/notebooks/tv_minimization_reconstruction_pdhg.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "if not importlib.util.find_spec('mr2'):\n",
    "    %pip install mrtwo[notebooks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Total-variation (TV)-minimization reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Image reconstruction\n",
    "Here, we use the Primal Dual Hybrid Gradient (PDHG) algorithm to reconstruct an image from 2D radial k-space data.\n",
    "\n",
    "Let $y$ denote the k-space data of the image $x_{\\mathrm{true}}$ sampled with an acquisition model $A$\n",
    "(Fourier transform, coil sensitivity maps, ...), i.e the forward problem is given as\n",
    "\n",
    "$ y = Ax_{\\mathrm{true}} + n, $\n",
    "\n",
    "where $n$ describes complex Gaussian noise. When using TV-minimization as regularization method, an approximation of\n",
    "$x_{\\mathrm{true}}$ is obtained by minimizing the following functional $\\mathcal{F}$ where $\\nabla$ is the\n",
    "discretized gradient operator.\n",
    "\n",
    "$ \\mathcal{F}(x) = \\frac{1}{2}||Ax - y||_2^2 + \\lambda \\| \\nabla x \\|_1, \\quad \\quad \\quad (1)$\n",
    "\n",
    "The minimization of the functional $\\mathcal{F}$ is a non-trivial task due to the presence of the operator\n",
    "$\\nabla$ in the non-differentiable $\\ell_1$-norm. A suitable algorithm to solve the problem is the\n",
    "PDHG-algorithm [[Chambolle \\& Pock, JMIV 2011](https://doi.org/10.1007%2Fs10851-010-0251-1)].\\\n",
    "PDHG is a method for solving problems of the form\n",
    "\n",
    "$ \\min_x f(K(x)) + g(x)  \\quad \\quad \\quad (2)$\n",
    "\n",
    "where $f$ and $g$ denote proper, convex, lower-semicontinous functionals and $K$ denotes a linear operator.\\\n",
    "PDHG essentially consists of three steps, which read as\n",
    "\n",
    "$z_{k+1} = \\mathrm{prox}_{\\sigma f^{\\ast}}(z_k + \\sigma K \\bar{x}_k)$\n",
    "\n",
    "$x_{k+1} = \\mathrm{prox}_{\\tau g}(x_k - \\tau K^H z_{k+1})$\n",
    "\n",
    "$\\bar{x}_{k+1} = x_{k+1} + \\theta(x_{k+1} - x_k)$,\n",
    "\n",
    "where $\\mathrm{prox}$ denotes the proximal operator and $f^{\\ast}$ denotes the convex conjugate of the\n",
    "functional $f$, $\\theta\\in [0,1]$ and step sizes $\\sigma, \\tau$ such that $\\sigma \\tau < 1/L^2$, where\n",
    "$L=\\|K\\|_2$ is the operator norm of the operator $K$.\n",
    "\n",
    "The first step is to recast problem (1) into the general form of (2) and then to apply the steps above\n",
    "in an iterative fashion. In the following, we use this approach to reconstruct a 2D radial image using\n",
    "`~mr2.algorithms.optimizers.pdhg`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Load data\n",
    "Our example data contains three scans acquired with a 2D golden angle radial trajectory and\n",
    "varying number of spokes:\n",
    "\n",
    "- ``radial2D_24spokes_golden_angle_with_traj.h5``\n",
    "- ``radial2D_96spokes_golden_angle_with_traj.h5``\n",
    "- ``radial2D_402spokes_golden_angle_with_traj.h5``\n",
    "\n",
    "We will use the 402 spokes as a reference and try to reconstruct the image from the 24 spokes data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show download details"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Download raw data from Zenodo\n",
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import zenodo_get\n",
    "\n",
    "tmp = tempfile.TemporaryDirectory()  # RAII, automatically cleaned up\n",
    "data_folder = Path(tmp.name)\n",
    "zenodo_get.download(\n",
    "    record='14617082', retry_attempts=5, output_dir=data_folder, access_token=os.environ.get('ZENODO_TOKEN')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mr2\n",
    "\n",
    "# We have embedded the trajectory information in the ISMRMRD files.\n",
    "kdata_402spokes = mr2.data.KData.from_file(\n",
    "    data_folder / 'radial2D_402spokes_golden_angle_with_traj.h5', mr2.data.traj_calculators.KTrajectoryIsmrmrd()\n",
    ")\n",
    "kdata_24spokes = mr2.data.KData.from_file(\n",
    "    data_folder / 'radial2D_24spokes_golden_angle_with_traj.h5', mr2.data.traj_calculators.KTrajectoryIsmrmrd()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Comparison reconstructions\n",
    "Before running the TV-minimization reconstruction, we first run a direct (adjoint) reconstruction\n",
    "using `~mr2.algorithms.reconstruction.DirectReconstruction` (see <project:direct_reconstruction.ipynb>)\n",
    "of both the 24 spokes and 402 spokes data to have a reference for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_reconstruction_402 = mr2.algorithms.reconstruction.DirectReconstruction(kdata_402spokes)\n",
    "direct_reconstruction_24 = mr2.algorithms.reconstruction.DirectReconstruction(kdata_24spokes)\n",
    "img_direct_402 = direct_reconstruction_402(kdata_402spokes)\n",
    "img_direct_24 = direct_reconstruction_24(kdata_24spokes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "We also run an iterative SENSE reconstruction (see <project:iterative_sense_reconstruction_radial2D.ipynb>) with early\n",
    "stopping of the 24 spokes data. We use it as a comparison and as an initial guess for the TV-minimization\n",
    "reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_reconstruction = mr2.algorithms.reconstruction.IterativeSENSEReconstruction(\n",
    "    kdata_24spokes,\n",
    "    n_iterations=8,\n",
    "    csm=direct_reconstruction_24.csm,\n",
    "    dcf=direct_reconstruction_24.dcf,\n",
    ")\n",
    "img_sense_24 = sense_reconstruction(kdata_24spokes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Set up the operator $A$\n",
    "Now, to set up the problem, we need to define the acquisition operator $A$, consisting of a\n",
    "`~mr2.operators.FourierOp` and a `~mr2.operators.SensitivityOp`, which applies the coil sensitivity maps\n",
    "(CSM) to the image. We reuse the CSMs estimated in the direct reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier_operator = mr2.operators.FourierOp.from_kdata(kdata_24spokes)\n",
    "\n",
    "assert direct_reconstruction_24.csm is not None\n",
    "csm_operator = direct_reconstruction_24.csm.as_operator()\n",
    "\n",
    "# The acquisition operator is the composition of the Fourier operator and the CSM operator\n",
    "acquisition_operator = fourier_operator @ csm_operator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Recast the problem to be able to apply PDHG\n",
    "To apply the PDHG algorithm, we need to recast the problem into the form of (2). We need to identify\n",
    "the functionals $f$ and $g$ and the operator $K$. We chose an identification for which both\n",
    "$\\mathrm{prox}_{\\sigma f^{\\ast}}$ and $\\mathrm{prox}_{\\tau g}$ are easy to compute:\n",
    "\n",
    "#### $f(z) = f(p,q) = f_1(p) + f_2(q) =  \\frac{1}{2}\\|p  - y\\|_2^2 + \\lambda \\| q \\|_1.$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "regularization_lambda = 1e-5\n",
    "f_1 = mr2.operators.functionals.L2NormSquared(target=kdata_24spokes.data)\n",
    "f_2 = regularization_lambda * mr2.operators.functionals.L1NormViewAsReal()\n",
    "f = mr2.operators.ProximableFunctionalSeparableSum(f_1, f_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### $K(x) = [A, \\nabla]^T$\n",
    "\n",
    "  where $\\nabla$ is the finite difference operator that computes the directional derivatives along the last two\n",
    "  dimensions (y,x), implemented as `~mr2.operators.FiniteDifferenceOp`, and\n",
    " `~mr2.operators.LinearOperatorMatrix` can be used to stack the operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "nabla = mr2.operators.FiniteDifferenceOp(dim=(-2, -1), mode='forward')\n",
    "K = mr2.operators.LinearOperatorMatrix(((acquisition_operator,), (nabla,)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### $g(x) = 0,$\n",
    "\n",
    "implemented as `~mr2.operators.functionals.ZeroFunctional`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "g = mr2.operators.functionals.ZeroFunctional()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "```{note}\n",
    "An obvious identification would have been\n",
    "- $f(x) = \\lambda \\| x\\|_1,$\n",
    "- $g(x) = \\frac{1}{2}\\|Ax  - y\\|_2^2,$\n",
    "- $K(x) = \\nabla x.$\n",
    "\n",
    "But to be able to compute $\\mathrm{prox}_{\\tau g}$, one would need to solve a linear system at each\n",
    "iteration, making this identification impractical.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "This identification allows us to compute the proximal operators of $f$ and $g$ easily.\n",
    "### Run PDHG for a certain number of iterations\n",
    "Now we can run the PDHG algorithm to solve the minimization problem. We use\n",
    "the iterative SENSE image as an initial value to speed up the convergence.\n",
    "```{note}\n",
    "We can use the `callback` parameter of `~mr2.algorithms.optimizers` to get some information\n",
    "about the progress. In the collapsed cell, we implement a simple callback function that print the status\n",
    "message\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show callback details"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This is a \"callback\" function that will be called after each iteration of the PDHG algorithm.\n",
    "# We use it here to print progress information.\n",
    "\n",
    "from mr2.algorithms.optimizers.pdhg import PDHGStatus\n",
    "\n",
    "\n",
    "def callback(optimizer_status: PDHGStatus) -> None:\n",
    "    \"\"\"Print the value of the objective functional every 16th iteration.\"\"\"\n",
    "    iteration = optimizer_status['iteration_number']\n",
    "    solution = optimizer_status['solution']\n",
    "    if iteration % 16 == 0:\n",
    "        print(f'Iteration {iteration: >3}: Objective = {optimizer_status[\"objective\"](*solution).item():.3e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "(img_pdhg_24,) = mr2.algorithms.optimizers.pdhg(\n",
    "    f=f,\n",
    "    g=g,\n",
    "    operator=K,\n",
    "    initial_values=(img_sense_24.data,),\n",
    "    max_iterations=257,\n",
    "    callback=callback,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "### Compare the results\n",
    "We now compare the results of the direct reconstruction, the iterative SENSE reconstruction, and the TV-minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show plotting details"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "def show_images(*images: torch.Tensor, titles: list[str] | None = None) -> None:\n",
    "    \"\"\"Plot images.\"\"\"\n",
    "    n_images = len(images)\n",
    "    _, axes = plt.subplots(1, n_images, squeeze=False, figsize=(n_images * 3, 3))\n",
    "    for i in range(n_images):\n",
    "        axes[0][i].imshow(images[i], cmap='gray')\n",
    "        axes[0][i].axis('off')\n",
    "        if titles:\n",
    "            axes[0][i].set_title(titles[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# see the collapsed cell above for the implementation of show_images\n",
    "show_images(\n",
    "    img_direct_402.rss().squeeze(),\n",
    "    img_direct_24.rss().squeeze(),\n",
    "    img_sense_24.rss().squeeze(),\n",
    "    img_pdhg_24.abs().squeeze(),\n",
    "    titles=['402 spokes', '24 spokes (direct)', '24 spokes (SENSE)', '24 spokes (PDHG)'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "### Ready-made reconstruction algorithm\n",
    "To make our life easier and to avoid the manual setup of the PDHG algorithm with total variation, we can use the\n",
    "`~mr2.algorithms.reconstruction.TotalVariationRegularizedReconstruction` class. This class\n",
    "takes care of setting up the PDHG algorithm and provides a simple interface to run the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_reconstruction = mr2.algorithms.reconstruction.TotalVariationRegularizedReconstruction(\n",
    "    kdata_24spokes,\n",
    "    csm=direct_reconstruction_24.csm,\n",
    "    max_iterations=257,\n",
    "    regularization_dim=(-2, -1),\n",
    "    regularization_weight=regularization_lambda,\n",
    ")\n",
    "img_tv_algo_24 = tv_reconstruction(kdata_24spokes)\n",
    "\n",
    "show_images(\n",
    "    img_pdhg_24.abs().squeeze(),\n",
    "    img_tv_algo_24.rss().squeeze(),\n",
    "    titles=['24 spokes (PDHG)', '24 spokes (TV Reco)'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "We can also check if the results are equal by comparing the actual image data.\n",
    "If the assert statement does not raise an exception, the results are equal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(img_pdhg_24.data, img_tv_algo_24.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Hurrah! We have successfully reconstructed an image from 24 spokes using TV-minimization.\n",
    "\n",
    "### Next steps\n",
    "Play around with the regularization weight and the number of iterations to see how they affect the final image.\n",
    "You can also try to use the 96 spokes data to see how the reconstruction quality improves with more spokes."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "mystnb,tags,-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
