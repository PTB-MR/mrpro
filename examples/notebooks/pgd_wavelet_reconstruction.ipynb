{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/PTB-MR/mrpro/blob/main/examples/notebooks/pgd_wavelet_reconstruction.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "if not importlib.util.find_spec('mrpro'):\n",
    "    %pip install mrpro[notebooks]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Accelerated proximal gradient descent (FISTA) reconstruction using wavelets and $\\ell_1$-norm minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Image reconstruction\n",
    "Here, we use a proximal gradient descent algorithm to reconstruct an image\n",
    "from 2D radial k-space data with wavelet regularization.\n",
    "In particular, we use the accelerated version known as FISTA (Fast Iterative Shrinkage-Thresholding Algorithm).\n",
    "\n",
    "Let $y$ denote the k-space data of the image $x_{\\mathrm{true}}$ sampled with an acquisition model $A$\n",
    "(Fourier transform, coil sensitivity maps, etc.), i.e the forward problem is given as\n",
    "\n",
    "$ y = Ax_{\\mathrm{true}} + n, $\n",
    "\n",
    "where $n$ describes complex Gaussian noise.\n",
    "\n",
    "As regularization method, here we employ wavelets, which are known to be suitable sparsifying transforms.\n",
    "We consider the following functional $\\mathcal{F}$:\n",
    "\n",
    "$ \\mathcal{F}(x) = \\frac{1}{2}||Ax - y||_2^2 + \\lambda \\| W x \\|_1, \\quad \\quad \\quad (1)$\n",
    "\n",
    "where $W$ is the discretized wavelet operator that maps the image domain to the wavelet domain,\n",
    "and $\\lambda >0$ is an appropriate regularization weight.\n",
    "\n",
    "The minimization of the functional $\\mathcal{F}$ is non-trivial due to\n",
    "the non-differentiable $\\ell_1$-norm and the presence of the wavelet operator.\n",
    "A possible algorithm to approach the solution of $(1)$ would be the primal dual hybrid gradient (PDHG)\n",
    "algorithm [[Chambolle \\& Pock, JMIV 2011](https://doi.org/10.1007%2Fs10851-010-0251-1)].\n",
    "However, exploiting the orthonormality of $W$, we can reformulate $(1)$ to solve the minimization problem\n",
    "in the wavelet domain and use a simpler algorithm. By defining the new variable $\\tilde{x} = Wx$\n",
    "(and thus, due to the orthonormality of $W$, $W^H \\tilde{x} = x$), the minimization problem becomes\n",
    "\n",
    "$ \\min_{\\tilde{x}} \\frac{1}{2}||\\tilde{A}\\tilde{x} - y||_2^2 + \\lambda \\| \\tilde{x} \\|_1,  \\quad \\quad \\quad (2)$\n",
    "\n",
    "where $\\tilde{A}:=A W^H$. A suitable algorithm to solve $(2)$ is the FISTA-algorithm\n",
    "[[Beck \\& Teboulle, SIAM Journal on Imaging Sciences 2009](https://epubs.siam.org/doi/10.1137/080716542)],\n",
    "which consists of an accelerated proximal gradient descent algorithm.\n",
    "\n",
    "In general, FISTA can be used to solve problems of the form\n",
    "\n",
    "$ \\min_x f(x) + g(x)  \\quad \\quad \\quad (3)$\n",
    "\n",
    "where $f$ is a convex, differentiable function with $L$-Lipschitz gradient $\\nabla f$,\n",
    "and $g$ is convex and possibly non-smooth.\n",
    "\n",
    "The main step of the minimization method is a proximal gradient step, which reads as\n",
    "\n",
    "$x_{k} = \\mathrm{prox}_{\\sigma g}(x_{k-1} - \\sigma \\nabla f({x}_{k-1}))$\n",
    "\n",
    "where $\\mathrm{prox}$ denotes the proximal operator and $\\sigma$ is\n",
    "an appropriate stepsize, ideally $\\sigma=\\frac{1}{L}$, with $L=L(\\nabla f)$ being\n",
    "the Lipschitz constant of $\\nabla f$.\n",
    "\n",
    "Moreover, FISTA has an additional step to accelerate the convergence. The following variable $z_{k+1}$\n",
    "is included, consisting of a linear interpolation\n",
    "of the previous two steps $x_{k}$ and $x_{k-1}$. So, for $t_1=1, z_1=x_0$:\n",
    "\n",
    "$x_{k} = \\mathrm{prox}_{\\sigma g}(z_{k} - \\sigma \\nabla f({z}_{k}))$\n",
    "\n",
    "$t_{k+1} = \\frac{1 + \\sqrt{1 + 4t_k^2}}{2}$\n",
    "\n",
    "$z_{k+1} = x_{k} + \\frac{t_k - 1}{t_{k+1}}(x_{k} - x_{k-1}).$\n",
    "\n",
    "As the Lipschitz constant $L$ is in general not known, and\n",
    "the interval of the stepsize $\\sigma\\in ( 0, \\frac{1}{|| \\tilde{A}||_2^2} )$ is crucial for the convergence,\n",
    "a backtracking step can  be performed to update the stepsize $\\sigma$ at every iteration. To do so,\n",
    "$\\sigma$ is iteratively reduced until reaching a stepsize that is the largest\n",
    "for which the quadratic approximation of $f$ at $z_{k}$\n",
    "is an upper bound for $f(x_{k})$.\n",
    "\n",
    "\n",
    "### Load data\n",
    "Our example data contains three scans acquired with a 2D golden angle radial trajectory and\n",
    "varying number of spokes:\n",
    "\n",
    "- ``radial2D_402spokes_golden_angle_with_traj.h5`` with 402 spokes\n",
    "- ``radial2D_96spokes_golden_angle_with_traj.h5`` with 96 spokes\n",
    "- ``radial2D_24spokes_golden_angle_with_traj.h5`` with 24 spokes\n",
    "\n",
    "We will use the 402 spokes as a reference and try to reconstruct the image from the 24 spokes data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show download details"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# ### Download raw data from Zenodo\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import zenodo_get\n",
    "\n",
    "tmp = tempfile.TemporaryDirectory()  # RAII, automatically cleaned up\n",
    "data_folder = Path(tmp.name)\n",
    "zenodo_get.download(record='14617082', retry_attempts=5, output_dir=data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load in the data from the ISMRMRD file\n",
    "import mrpro\n",
    "\n",
    "# We have embedded the trajectory information in the ISMRMRD files.\n",
    "kdata_402spokes = mrpro.data.KData.from_file(\n",
    "    data_folder / 'radial2D_402spokes_golden_angle_with_traj.h5', mrpro.data.traj_calculators.KTrajectoryIsmrmrd()\n",
    ")\n",
    "kdata_24spokes = mrpro.data.KData.from_file(\n",
    "    data_folder / 'radial2D_24spokes_golden_angle_with_traj.h5', mrpro.data.traj_calculators.KTrajectoryIsmrmrd()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Comparison reconstructions\n",
    "Before running the wavelets-based reconstruction, we first run a direct (adjoint) reconstruction\n",
    "using `~mrpro.algorithms.reconstruction.DirectReconstruction` (see <project:direct_reconstruction.ipynb>)\n",
    "of both the 24 spokes and 402 spokes data to have a reference for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_reconstruction_402 = mrpro.algorithms.reconstruction.DirectReconstruction(kdata_402spokes)\n",
    "direct_reconstruction_24 = mrpro.algorithms.reconstruction.DirectReconstruction(kdata_24spokes)\n",
    "img_direct_402 = direct_reconstruction_402(kdata_402spokes)\n",
    "img_direct_24 = direct_reconstruction_24(kdata_24spokes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "We also run an iterative SENSE reconstruction (see <project:iterative_sense_reconstruction_radial2D.ipynb>) with early\n",
    "stopping of the 24 spokes data. We use it as a comparison and as an initial guess for FISTA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "sense_reconstruction = mrpro.algorithms.reconstruction.IterativeSENSEReconstruction(\n",
    "    kdata_24spokes,\n",
    "    n_iterations=8,\n",
    "    csm=direct_reconstruction_24.csm,\n",
    "    dcf=direct_reconstruction_24.dcf,\n",
    ")\n",
    "img_sense_24 = sense_reconstruction(kdata_24spokes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Set up the operator $\\tilde{A}$\n",
    "Define the wavelet operator $W$ and set $\\tilde{A} = A W^H = F C W^H $, where $F$ is the Fourier\n",
    "operator, $C$ denotes the coil sensitivity maps and $W^H$ represents the adjoint wavelet operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourier_operator = direct_reconstruction_24.fourier_op\n",
    "\n",
    "assert direct_reconstruction_24.csm is not None\n",
    "csm_operator = direct_reconstruction_24.csm.as_operator()\n",
    "\n",
    "# Define the wavelet operator\n",
    "wavelet_operator = mrpro.operators.WaveletOp(\n",
    "    domain_shape=img_direct_24.data.shape[-2:], dim=(-2, -1), wavelet_name='db4', level=None\n",
    ")\n",
    "\n",
    "# Create the full acquisition operator $\\tilde{A}$ including the adjoint of the wavelet operator\n",
    "acquisition_operator = fourier_operator @ csm_operator @ wavelet_operator.H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "### Set up the problem\n",
    "In order to apply FISTA to solve $(2)$, we identify $f$ and $g$ from $(3)$ as\n",
    "\n",
    "$f(\\tilde{x}) = \\frac{1}{2}\\|\\tilde{A}\\tilde{x}  - y\\|_2^2,$\n",
    "\n",
    "$g(\\tilde{x}) = \\lambda \\| \\tilde{x}\\|_1.$\n",
    "\n",
    "From this, we see that FISTA is a good choice to solve $(2)$,\n",
    "as $\\mathrm{prox}_g$ is given by simple soft-thresholding.\n",
    "\n",
    "After having run the algorithm for $T$ iterations, the obtained solution $\\tilde{x}_{T}$\n",
    "is in the wavelet domain and needs to be mapped back to image domain.\n",
    "Thus, we apply the adjoint of the wavelet transform and obtain the solution $x_{\\text{opt}}$\n",
    "in image domain as\n",
    "\n",
    "$x_{\\text{opt}} := W^H \\tilde{x}_{T}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization parameter for the $\\ell_1$-norm\n",
    "regularization_parameter = 1e-5\n",
    "\n",
    "# Set up the problem by using the previously described identification\n",
    "l2 = 0.5 * mrpro.operators.functionals.L2NormSquared(target=kdata_24spokes.data, divide_by_n=False)\n",
    "l1 = mrpro.operators.functionals.L1NormViewAsReal(divide_by_n=False)\n",
    "\n",
    "f = l2 @ acquisition_operator\n",
    "g = regularization_parameter * l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show callback details"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# This is a \"callback\" function to track the value of the objective functional f(x) + g(x)\n",
    "# and stepsize update\n",
    "from mrpro.algorithms.optimizers.pgd import PGDStatus\n",
    "\n",
    "\n",
    "def callback(optimizer_status: PGDStatus) -> None:\n",
    "    \"\"\"Print the value of the objective functional every 8th iteration.\"\"\"\n",
    "    iteration = optimizer_status['iteration_number']\n",
    "    solution = optimizer_status['solution']\n",
    "    if iteration % 8 == 0:\n",
    "        print(\n",
    "            f'{iteration}: {optimizer_status[\"objective\"](*solution).item()}, stepsize: {optimizer_status[\"stepsize\"]}'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Run FISTA for a certain number of iterations\n",
    "Now we can run the FISTA algorithm to solve the minimization problem. As an initial guess,\n",
    "we use the wavelet-coefficients of the iterative SENSE image to speed up the convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the stepsize based on the operator norm of the acquisition operator and run FISTA\n",
    "import torch\n",
    "\n",
    "# initialize FISTA with adjoint solution\n",
    "initial_values = wavelet_operator(img_direct_24.data)\n",
    "\n",
    "op_norm = acquisition_operator.operator_norm(\n",
    "    initial_value=torch.randn_like(initial_values[0]), dim=(-2, -1), max_iterations=36\n",
    ").item()\n",
    "\n",
    "# define step size with a security factor to ensure to\n",
    "# have stepsize $t \\in (0, L(f))$, where $L(f)=1/\\|\\tilde{A}\\|_2^2)$ is\n",
    "# the Lipschitz constant of the functional $f$\n",
    "stepsize = 0.9 * (1 / op_norm**2)\n",
    "\n",
    "(img_wave_pgd_24,) = mrpro.algorithms.optimizers.pgd(\n",
    "    f=f,\n",
    "    g=g,\n",
    "    initial_value=initial_values,\n",
    "    stepsize=stepsize,\n",
    "    max_iterations=48,\n",
    "    backtrack_factor=1.0,\n",
    "    callback=callback,\n",
    ")\n",
    "\n",
    "# map the solution back to image domain\n",
    "(img_pgd_24,) = wavelet_operator.H(img_wave_pgd_24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "```{note}\n",
    "When defining the functional $f$ with the argument `divide_b_n=True`, one needs to be careful when setting\n",
    "the stepsize to be used in FISTA. The reason is that the Lipschitz-constant of the gradient of the functional\n",
    "$f_N(\\tilde{x}) = 1/(2N)\\,\\|\\tilde{A}\\tilde{x} - y\\|_2^2$, where $y\\in\\mathbb{C}^N$, is no longer given\n",
    "by the squared operator norm of $\\tilde{A}$, but rather by the squared operator norm of the scaled\n",
    "operator $1/N \\cdot \\tilde{A}$. Thus, the Lipschitz constant $L(\\nabla f_N)$ must be appropriately scaled,\n",
    "i.e. $L(\\nabla f_N) = N \\cdot L( \\nabla f)$.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Results\n",
    "We compare the result of the wavelet regularized reconstruction with the\n",
    "iterative SENSE and direct reconstruction result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "mystnb": {
     "code_prompt_show": "Show plotting details"
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "\n",
    "def show_images(*images: torch.Tensor, titles: list[str] | None = None) -> None:\n",
    "    \"\"\"Plot images.\"\"\"\n",
    "    n_images = len(images)\n",
    "    _, axes = plt.subplots(1, n_images, squeeze=False, figsize=(n_images * 3, 3))\n",
    "    for i in range(n_images):\n",
    "        axes[0][i].imshow(images[i], cmap='gray', clim=[0, 3e-4])\n",
    "        axes[0][i].axis('off')\n",
    "        if titles:\n",
    "            axes[0][i].set_title(titles[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# see the collapsed cell above for the implementation of show_images\n",
    "show_images(\n",
    "    img_direct_402.rss().squeeze(),\n",
    "    img_direct_24.rss().squeeze(),\n",
    "    img_sense_24.rss().squeeze(),\n",
    "    img_pgd_24.abs().squeeze(),\n",
    "    titles=['402 spokes', '24 spokes (Direct)', '24 spokes (SENSE)', '24 spokes (PGD)'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "Congratulations! We have successfully reconstructed an image from 24 spokes using wavelets.\n",
    "\n",
    "### Next steps\n",
    "Not happy with the results? Play around with the regularization weight, the number of iterations, the\n",
    "number of levels in the wavelet decomposition or the backtracking factor to see how they affect the final image.\n",
    "Still not happy? Maybe worth giving a try to total variation (TV)-minimization as an alternative\n",
    "regularization method (see <project:tv_minimization_reconstruction_pdhg.ipynb>).\n",
    "You can also try to use the 96 spokes data to see how the reconstruction quality improves with more spokes."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "jupytext": {
   "cell_metadata_filter": "mystnb,tags,-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
