

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>mrpro.operators.SliceProjectionOp &mdash; mrpro</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=16f952a1" />

  
      <script src="../../../_static/jquery.js?v=5d32c60e"></script>
      <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            mrpro
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api.html">API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../user_guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../contributor_guide.html">Contributor Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../faq.html">FAQ</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">mrpro</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">mrpro.operators.SliceProjectionOp</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for mrpro.operators.SliceProjectionOp</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Class for 3D-&gt;2D Projection Operator.&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Sequence</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">TypeAlias</span>

<span class="kn">import</span> <span class="nn">einops</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">numpy._typing</span> <span class="kn">import</span> <span class="n">_NestedSequence</span> <span class="k">as</span> <span class="n">NestedSequence</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">Tensor</span>

<span class="kn">from</span> <span class="nn">mrpro.data.Rotation</span> <span class="kn">import</span> <span class="n">Rotation</span>
<span class="kn">from</span> <span class="nn">mrpro.data.SpatialDimension</span> <span class="kn">import</span> <span class="n">SpatialDimension</span>
<span class="kn">from</span> <span class="nn">mrpro.operators.LinearOperator</span> <span class="kn">import</span> <span class="n">LinearOperator</span>
<span class="kn">from</span> <span class="nn">mrpro.utils.slice_profiles</span> <span class="kn">import</span> <span class="n">SliceSmoothedRectangular</span>


<span class="k">class</span> <span class="nc">_MatrixMultiplicationCtx</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">function</span><span class="o">.</span><span class="n">FunctionCtx</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Autograd context for matrix multiplication, used for type hinting.&quot;&quot;&quot;</span>

    <span class="n">x_is_complex</span><span class="p">:</span> <span class="nb">bool</span>
    <span class="n">saved_tensors</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]</span>


<span class="k">class</span> <span class="nc">_MatrixMultiplication</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">Function</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Helper for matrix multiplication.</span>

<span class="sd">    For sparse matrices, it can be more efficient to have a</span>
<span class="sd">    separate representation of the adjoint matrix to be used</span>
<span class="sd">    in the backward pass.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">matrix</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">matrix_adjoint</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>  <span class="c1"># noqa: ARG004</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">is_complex</span><span class="p">()</span> <span class="o">==</span> <span class="n">matrix</span><span class="o">.</span><span class="n">is_complex</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">matrix</span> <span class="o">@</span> <span class="n">x</span>
        <span class="c1"># required for sparse matrices to support mixed complex/real multiplication</span>
        <span class="k">elif</span> <span class="n">x</span><span class="o">.</span><span class="n">is_complex</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">complex</span><span class="p">(</span><span class="n">matrix</span> <span class="o">@</span> <span class="n">x</span><span class="o">.</span><span class="n">real</span><span class="p">,</span> <span class="n">matrix</span> <span class="o">@</span> <span class="n">x</span><span class="o">.</span><span class="n">imag</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">complex</span><span class="p">(</span><span class="n">matrix</span><span class="o">.</span><span class="n">real</span> <span class="o">@</span> <span class="n">x</span><span class="p">,</span> <span class="n">matrix</span><span class="o">.</span><span class="n">imag</span> <span class="o">@</span> <span class="n">x</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">setup_context</span><span class="p">(</span>
        <span class="n">ctx</span><span class="p">:</span> <span class="n">_MatrixMultiplicationCtx</span><span class="p">,</span>
        <span class="n">inputs</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">,</span> <span class="n">Tensor</span><span class="p">],</span>
        <span class="n">outputs</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">],</span>  <span class="c1"># noqa: ARG004</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">matrix_adjoint</span> <span class="o">=</span> <span class="n">inputs</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">x_is_complex</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">is_complex</span><span class="p">()</span>
        <span class="n">ctx</span><span class="o">.</span><span class="n">save_for_backward</span><span class="p">(</span><span class="n">matrix_adjoint</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">:</span> <span class="n">_MatrixMultiplicationCtx</span><span class="p">,</span> <span class="o">*</span><span class="n">grad_output</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">]:</span>
        <span class="p">(</span><span class="n">matrix_adjoint</span><span class="p">,)</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">saved_tensors</span>
        <span class="k">if</span> <span class="n">ctx</span><span class="o">.</span><span class="n">x_is_complex</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">matrix_adjoint</span><span class="o">.</span><span class="n">is_complex</span><span class="p">()</span> <span class="o">==</span> <span class="n">grad_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">is_complex</span><span class="p">():</span>
                <span class="n">grad_x</span> <span class="o">=</span> <span class="n">matrix_adjoint</span> <span class="o">@</span> <span class="n">grad_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">matrix_adjoint</span><span class="o">.</span><span class="n">is_complex</span><span class="p">():</span>
                <span class="n">grad_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">complex</span><span class="p">(</span><span class="n">matrix_adjoint</span><span class="o">.</span><span class="n">real</span> <span class="o">@</span> <span class="n">grad_output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">matrix_adjoint</span><span class="o">.</span><span class="n">imag</span> <span class="o">@</span> <span class="n">grad_output</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">grad_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">complex</span><span class="p">(</span><span class="n">matrix_adjoint</span> <span class="o">@</span> <span class="n">grad_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">real</span><span class="p">,</span> <span class="n">matrix_adjoint</span> <span class="o">@</span> <span class="n">grad_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imag</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># real grad</span>
            <span class="n">grad_x</span> <span class="o">=</span> <span class="n">matrix_adjoint</span><span class="o">.</span><span class="n">real</span> <span class="o">@</span> <span class="n">grad_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">real</span>
            <span class="k">if</span> <span class="n">matrix_adjoint</span><span class="o">.</span><span class="n">is_complex</span><span class="p">()</span> <span class="ow">and</span> <span class="n">grad_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">is_complex</span><span class="p">():</span>
                <span class="n">grad_x</span> <span class="o">-=</span> <span class="n">matrix_adjoint</span><span class="o">.</span><span class="n">imag</span> <span class="o">@</span> <span class="n">grad_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imag</span>
        <span class="k">return</span> <span class="n">grad_x</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>


<span class="n">TensorFunction</span><span class="p">:</span> <span class="n">TypeAlias</span> <span class="o">=</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">Tensor</span><span class="p">]</span>


<div class="viewcode-block" id="SliceProjectionOp">
<a class="viewcode-back" href="../../../_autosummary/mrpro.operators.SliceProjectionOp.html#mrpro.operators.SliceProjectionOp">[docs]</a>
<span class="k">class</span> <span class="nc">SliceProjectionOp</span><span class="p">(</span><span class="n">LinearOperator</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Slice Projection Operator.</span>

<span class="sd">    This operation samples from a 3D Volume a slice with a given rotation and shift</span>
<span class="sd">    (relative to the center of the volume) according to the slice_profile.</span>
<span class="sd">    It can, for example, be used to describe the slice selection of a 2D MRI sequence</span>
<span class="sd">    from the 3D Volume.</span>

<span class="sd">    The projection will be done by sparse matrix multiplication.</span>

<span class="sd">    Rotation, shift, and profile can have (multiple) batch dimensions. These dimensions will</span>
<span class="sd">    be broadcasted to a common shape and added to the front of the volume.</span>
<span class="sd">    Different settings for different volume batches are NOT supported, consider creating multiple</span>
<span class="sd">    operators if required.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">matrix</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span>
    <span class="n">matrix_adjoint</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span>

<div class="viewcode-block" id="SliceProjectionOp.__init__">
<a class="viewcode-back" href="../../../_autosummary/mrpro.operators.SliceProjectionOp.html#mrpro.operators.SliceProjectionOp.__init__">[docs]</a>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">input_shape</span><span class="p">:</span> <span class="n">SpatialDimension</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">slice_rotation</span><span class="p">:</span> <span class="n">Rotation</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">slice_shift</span><span class="p">:</span> <span class="nb">float</span> <span class="o">|</span> <span class="n">Tensor</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">slice_profile</span><span class="p">:</span> <span class="n">TensorFunction</span> <span class="o">|</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">|</span> <span class="n">NestedSequence</span><span class="p">[</span><span class="n">TensorFunction</span><span class="p">]</span> <span class="o">|</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2.0</span><span class="p">,</span>
        <span class="n">optimize_for</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s1">&#39;forward&#39;</span><span class="p">,</span> <span class="s1">&#39;adjoint&#39;</span><span class="p">,</span> <span class="s1">&#39;both&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;both&#39;</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a module that represents the &#39;projection&#39; of a volume onto a plane.</span>

<span class="sd">        This operation samples from a 3D Volume a slice with a given rotation and shift</span>
<span class="sd">        (relative to the center of the volume) according to the slice_profile.</span>
<span class="sd">        It can, for example, be used to describe the slice selection of a 2D MRI sequence</span>
<span class="sd">        from the 3D Volume.</span>

<span class="sd">        The projection will be done by sparse matrix multiplication.</span>

<span class="sd">        Rotation, shift, and profile can have (multiple) batch dimensions. These dimensions will</span>
<span class="sd">        be broadcasted to a common shape and added to the front of the volume.</span>
<span class="sd">        Different settings for different volume batches are NOT supported, consider creating multiple</span>
<span class="sd">        operators if required.</span>


<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_shape</span>
<span class="sd">            Shape of the 3D volume to sample from (z, y, x)</span>
<span class="sd">        slice_rotation</span>
<span class="sd">            Rotation that describes the orientation of the plane. If None,</span>
<span class="sd">            an identity rotation is used.</span>
<span class="sd">        slice_shift</span>
<span class="sd">            Offset of the plane in the volume perpendicular plane from the center of the volume.</span>
<span class="sd">            (The center of a 4 pixel volume is between 1 and 2.)</span>
<span class="sd">        slice_profile</span>
<span class="sd">            A function returning the relative intensity of the slice profile at a position x</span>
<span class="sd">            (relative to the nominal profile center). This can also be a nested Sequence or an</span>
<span class="sd">            numpy array of functions.</span>
<span class="sd">            If it is a single float, it will be interpreted as the FWHM of a rectangular profile.</span>
<span class="sd">        optimize_for</span>
<span class="sd">            Whether to optimize for forward or adjoint operation or both.</span>
<span class="sd">            Optimizing for both takes more memory but is faster for both operations.</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">slice_profile</span><span class="p">,</span> <span class="nb">float</span> <span class="o">|</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">slice_profile</span> <span class="o">=</span> <span class="n">SliceSmoothedRectangular</span><span class="p">(</span><span class="n">slice_profile</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="n">slice_profile_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">slice_profile</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">slice_rotation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">slice_rotation</span> <span class="o">=</span> <span class="n">Rotation</span><span class="o">.</span><span class="n">identity</span><span class="p">()</span>

        <span class="n">max_shape</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">input_shape</span><span class="o">.</span><span class="n">z</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">_find_width</span><span class="p">(</span><span class="n">slice_profile</span><span class="p">:</span> <span class="n">TensorFunction</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
            <span class="c1"># figure out how far along the profile we have to consider values</span>
            <span class="c1"># clip up to 0.01 of intensity on both sides</span>
            <span class="n">test_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">max_shape</span><span class="p">,</span> <span class="n">max_shape</span><span class="p">,</span> <span class="n">max_shape</span><span class="p">)</span>
            <span class="n">profile</span> <span class="o">=</span> <span class="n">slice_profile</span><span class="p">(</span><span class="n">test_values</span><span class="p">)</span>
            <span class="n">cdf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">profile</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">profile</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
            <span class="n">left</span> <span class="o">=</span> <span class="n">test_values</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cdf</span> <span class="o">&gt;</span> <span class="mf">0.01</span><span class="p">)]</span>
            <span class="n">right</span> <span class="o">=</span> <span class="n">test_values</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cdf</span> <span class="o">&gt;</span> <span class="mf">0.99</span><span class="p">)]</span>
            <span class="k">return</span> <span class="nb">int</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">left</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">right</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">()))</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="n">widths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">_find_width</span><span class="p">)(</span><span class="n">slice_profile_array</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">_at_least_width_1</span><span class="p">(</span><span class="n">slice_profile</span><span class="p">:</span> <span class="n">TensorFunction</span><span class="p">):</span>
            <span class="n">test_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">slice_profile</span><span class="p">(</span><span class="n">test_values</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">1e-6</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">np</span><span class="o">.</span><span class="n">vectorize</span><span class="p">(</span><span class="n">_at_least_width_1</span><span class="p">)(</span><span class="n">slice_profile_array</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s1">&#39;The slice profile must have a width of at least 1 voxel,&#39;</span>
                <span class="s1">&#39; i.e. the profile should be greater then 1e-6 in (-0.5,0.5)&#39;</span>
            <span class="p">)</span>

        <span class="n">slice_shift_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">atleast_1d</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">slice_shift</span><span class="p">))</span>
        <span class="n">batch_shapes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">broadcast_shapes</span><span class="p">(</span><span class="n">slice_rotation</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">slice_shift_tensor</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">slice_profile_array</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">rotation_quats</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">slice_rotation</span><span class="o">.</span><span class="n">as_quat</span><span class="p">(),</span> <span class="p">(</span><span class="o">*</span><span class="n">batch_shapes</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        <span class="n">slice_rotation</span> <span class="o">=</span> <span class="n">Rotation</span><span class="p">(</span><span class="n">rotation_quats</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">copy</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">slice_shift_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">slice_shift_tensor</span><span class="p">,</span> <span class="n">batch_shapes</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">slice_profile_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">slice_profile_array</span><span class="p">,</span> <span class="n">batch_shapes</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="n">widths</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">(</span><span class="n">widths</span><span class="p">,</span> <span class="n">batch_shapes</span><span class="p">)</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>

        <span class="n">matrices</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">SliceProjectionOp</span><span class="o">.</span><span class="n">projection_matrix</span><span class="p">(</span>
                <span class="n">input_shape</span><span class="p">,</span>
                <span class="n">SpatialDimension</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_shape</span><span class="p">,</span> <span class="n">max_shape</span><span class="p">),</span>
                <span class="n">offset</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">shift</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]),</span>
                <span class="n">slice_function</span><span class="o">=</span><span class="n">f</span><span class="p">,</span>
                <span class="n">rotation</span><span class="o">=</span><span class="n">rot</span><span class="p">,</span>
                <span class="n">w</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">w</span><span class="p">),</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">rot</span><span class="p">,</span> <span class="n">shift</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">slice_rotation</span><span class="p">,</span> <span class="n">slice_shift_tensor</span><span class="p">,</span> <span class="n">slice_profile_array</span><span class="p">,</span> <span class="n">widths</span><span class="p">,</span> <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="p">]</span>
        <span class="n">matrix</span> <span class="o">=</span> <span class="n">SliceProjectionOp</span><span class="o">.</span><span class="n">join_matrices</span><span class="p">(</span><span class="n">matrices</span><span class="p">)</span>

        <span class="c1"># in csr format the matmul is faster, but saving one for forward and adjoint takes more memory</span>
        <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
            <span class="c1"># beta status in pytorch causes a warning to be printed</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s1">&#39;Sparse&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">optimize_for</span> <span class="o">==</span> <span class="s1">&#39;forward&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;matrix&#39;</span><span class="p">,</span> <span class="n">matrix</span><span class="o">.</span><span class="n">to_sparse_csr</span><span class="p">())</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">matrix_adjoint</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">elif</span> <span class="n">optimize_for</span> <span class="o">==</span> <span class="s1">&#39;adjoint&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;matrix_adjoint&#39;</span><span class="p">,</span> <span class="n">matrix</span><span class="o">.</span><span class="n">H</span><span class="o">.</span><span class="n">to_sparse_csr</span><span class="p">())</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">matrix</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="k">elif</span> <span class="n">optimize_for</span> <span class="o">==</span> <span class="s1">&#39;both&#39;</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;matrix_adjoint&#39;</span><span class="p">,</span> <span class="n">matrix</span><span class="o">.</span><span class="n">H</span><span class="o">.</span><span class="n">to_sparse_csr</span><span class="p">())</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;matrix&#39;</span><span class="p">,</span> <span class="n">matrix</span><span class="o">.</span><span class="n">to_sparse_csr</span><span class="p">())</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;optimize_for must be one of &#39;forward&#39;, &#39;adjoint&#39;, &#39;both&#39;&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_range_shape</span><span class="p">:</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="o">*</span><span class="n">batch_shapes</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">max_shape</span><span class="p">,</span> <span class="n">max_shape</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_domain_shape</span> <span class="o">=</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">zyx</span></div>


<div class="viewcode-block" id="SliceProjectionOp.forward">
<a class="viewcode-back" href="../../../_autosummary/mrpro.operators.SliceProjectionOp.html#mrpro.operators.SliceProjectionOp.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transform from a 3D Volume to a 2D Slice.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x</span>
<span class="sd">            3D Volume with shape (..., z, y, x)</span>
<span class="sd">            with z, y, x matching the input_shape</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        A 2D slice with shape (..., 1, max(z, y, x), (max(z, y, x)))</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">match</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">matrix</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">matrix_adjoint</span><span class="p">):</span>
            <span class="c1"># selection based on the optimize_for setting</span>
            <span class="k">case</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Either matrix or matrix adjoint must be set&#39;</span><span class="p">)</span>
            <span class="k">case</span> <span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">if</span> <span class="n">matrix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">matrix_adjoint</span> <span class="o">=</span> <span class="n">matrix</span><span class="o">.</span><span class="n">H</span>
            <span class="k">case</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">matrix_adjoint</span><span class="p">)</span> <span class="k">if</span> <span class="n">matrix_adjoint</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">matrix</span> <span class="o">=</span> <span class="n">matrix_adjoint</span><span class="o">.</span><span class="n">H</span>
            <span class="k">case</span> <span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">matrix_adjoint</span><span class="p">):</span>
                <span class="o">...</span>

        <span class="c1"># For the (unusual case) of batched volumes, we will apply for each element in series</span>
        <span class="n">xflat</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;... x y z -&gt; (...) (x y z)&#39;</span><span class="p">))</span>
        <span class="n">yl</span> <span class="o">=</span> <span class="p">[</span><span class="n">_MatrixMultiplication</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">matrix</span><span class="p">,</span> <span class="n">matrix_adjoint</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">xflat</span><span class="p">]</span>

        <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">el</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_range_shape</span><span class="p">)</span> <span class="k">for</span> <span class="n">el</span> <span class="ow">in</span> <span class="n">yl</span><span class="p">],</span> <span class="o">-</span><span class="mi">4</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">4</span><span class="p">],</span> <span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[:</span><span class="o">-</span><span class="mi">3</span><span class="p">],</span> <span class="o">*</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">:])</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">y</span><span class="p">,)</span></div>


<div class="viewcode-block" id="SliceProjectionOp.adjoint">
<a class="viewcode-back" href="../../../_autosummary/mrpro.operators.SliceProjectionOp.html#mrpro.operators.SliceProjectionOp.adjoint">[docs]</a>
    <span class="k">def</span> <span class="nf">adjoint</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="n">Tensor</span><span class="p">,]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Transform from a 2D slice to a 3D Volume.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x</span>
<span class="sd">            2D Slice with shape (..., 1, max(z, y, x), (max(z, y, x)))</span>
<span class="sd">            with z, y, x matching the input_shape</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        A 3D Volume with shape (..., z, y, x)</span>
<span class="sd">           with z, y, x matching the input_shape</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">match</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">matrix</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">matrix_adjoint</span><span class="p">):</span>
            <span class="c1"># selection based on the optimize_for setting</span>
            <span class="k">case</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s1">&#39;Either matrix or matrix adjoint must be set&#39;</span><span class="p">)</span>
            <span class="k">case</span> <span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">if</span> <span class="n">matrix</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">matrix_adjoint</span> <span class="o">=</span> <span class="n">matrix</span><span class="o">.</span><span class="n">H</span>
            <span class="k">case</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">matrix_adjoint</span><span class="p">)</span> <span class="k">if</span> <span class="n">matrix_adjoint</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">matrix</span> <span class="o">=</span> <span class="n">matrix_adjoint</span><span class="o">.</span><span class="n">H</span>
            <span class="k">case</span> <span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">matrix_adjoint</span><span class="p">):</span>
                <span class="o">...</span>

        <span class="c1"># For the (unusual case) of batched volumes, we will apply for each element in series</span>
        <span class="n">n_batchdim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_range_shape</span><span class="p">)</span> <span class="o">-</span> <span class="mi">3</span>
        <span class="c1"># x_domainbatch_range has all volume batch dimensions moved to the front</span>
        <span class="n">x_domainbatch_range</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">moveaxis</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_batchdim</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">3</span><span class="p">)),</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">3</span> <span class="o">-</span> <span class="n">n_batchdim</span><span class="p">)))</span>
        <span class="c1"># x_flatdomainbatch_flatrange is 2D with shape</span>
        <span class="c1"># (all batch dimensions of the volume flattened, all range dimensions flattened)</span>
        <span class="n">x_domainbatch_flatrange</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">atleast_2d</span><span class="p">(</span><span class="n">x_domainbatch_range</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">start_dim</span><span class="o">=-</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_range_shape</span><span class="p">)))</span>
        <span class="n">x_flatdomainbatch_flatrange</span> <span class="o">=</span> <span class="n">x_domainbatch_flatrange</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">end_dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span>
        <span class="c1"># y_flatdomainbatch has shape (all batch dimensions of the volume flattened, *range dimensions)</span>
        <span class="n">y_flatdomainbatch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="n">_MatrixMultiplication</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">matrix_adjoint</span><span class="p">,</span> <span class="n">matrix</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_domain_shape</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_flatdomainbatch_flatrange</span>
            <span class="p">]</span>
        <span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">y_flatdomainbatch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">n_batchdim</span><span class="p">:</span><span class="o">-</span><span class="mi">3</span><span class="p">],</span> <span class="o">*</span><span class="n">y_flatdomainbatch</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">y</span><span class="p">,)</span></div>


<div class="viewcode-block" id="SliceProjectionOp.join_matrices">
<a class="viewcode-back" href="../../../_autosummary/mrpro.operators.SliceProjectionOp.html#mrpro.operators.SliceProjectionOp.join_matrices">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">join_matrices</span><span class="p">(</span><span class="n">matrices</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Tensor</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Join multiple sparse matrices into a block diagonal matrix.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        matrices</span>
<span class="sd">            List of sparse matrices to join by stacking them as a block diagonal matrix</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">target</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">source</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">matrices</span><span class="p">):</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">m</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">matrices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;all matrices should have the same shape&#39;</span><span class="p">)</span>
            <span class="n">c</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">coalesce</span><span class="p">()</span>  <span class="c1"># we want unique indices</span>
            <span class="p">(</span><span class="n">ctarget</span><span class="p">,</span> <span class="n">csource</span><span class="p">)</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">indices</span><span class="p">()</span>
            <span class="n">values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
            <span class="n">source</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">csource</span><span class="p">)</span>
            <span class="n">ctarget</span> <span class="o">=</span> <span class="n">ctarget</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">target</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ctarget</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
            <span class="c1"># beta status in pytorch causes a warning to be printed</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s1">&#39;Sparse&#39;</span><span class="p">)</span>
            <span class="n">matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo_tensor</span><span class="p">(</span>
                <span class="n">indices</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">target</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">source</span><span class="p">)]),</span>
                <span class="n">values</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">values</span><span class="p">),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">matrices</span><span class="p">)</span> <span class="o">*</span> <span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">m</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">matrix</span></div>


<div class="viewcode-block" id="SliceProjectionOp.projection_matrix">
<a class="viewcode-back" href="../../../_autosummary/mrpro.operators.SliceProjectionOp.html#mrpro.operators.SliceProjectionOp.projection_matrix">[docs]</a>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">projection_matrix</span><span class="p">(</span>
        <span class="n">input_shape</span><span class="p">:</span> <span class="n">SpatialDimension</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">output_shape</span><span class="p">:</span> <span class="n">SpatialDimension</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">rotation</span><span class="p">:</span> <span class="n">Rotation</span><span class="p">,</span>
        <span class="n">offset</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">,</span>
        <span class="n">w</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">slice_function</span><span class="p">:</span> <span class="n">TensorFunction</span><span class="p">,</span>
        <span class="n">rotation_center</span><span class="p">:</span> <span class="n">Tensor</span> <span class="o">|</span> <span class="kc">None</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Create a sparse matrix that represents the projection of a volume onto a plane.</span>

<span class="sd">        Outside the volume values are approximately zero padded</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        input_shape</span>
<span class="sd">            Shape of the volume to sample from</span>
<span class="sd">        output_shape</span>
<span class="sd">            Shape of the resulting plane, 2D. Only the x and y values are used.</span>
<span class="sd">        rotation</span>
<span class="sd">            Rotation that describes the orientation of the plane</span>
<span class="sd">        offset: Tensor</span>
<span class="sd">            Shift of the plane from the center of the volume in the rotated coordinate system</span>
<span class="sd">            in units of the 3D volume, order z, y, x</span>
<span class="sd">        w: int</span>
<span class="sd">            Factor that determines the number of pixels that are considered in the projection along</span>
<span class="sd">            the slice profile direction.</span>
<span class="sd">        slice_function</span>
<span class="sd">            Function that describes the slice profile.</span>
<span class="sd">        rotation_center</span>
<span class="sd">            Center of rotation, if None the center of the volume is used,</span>
<span class="sd">            i.e. for 4 pixels 0 1 2 3 it is between 1 and 2</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.sparse_coo_matrix</span>
<span class="sd">            Sparse matrix that represents the projection of the volume onto the plane</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">output_shape</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="n">output_shape</span><span class="o">.</span><span class="n">y</span>

        <span class="n">start_x</span><span class="p">,</span> <span class="n">start_y</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">input_shape</span><span class="o">.</span><span class="n">x</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
            <span class="p">(</span><span class="n">input_shape</span><span class="o">.</span><span class="n">y</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">pixel_coord_y_x_zyx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
            <span class="p">[</span>
                <span class="p">(</span><span class="n">input_shape</span><span class="o">.</span><span class="n">z</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span>  <span class="c1"># z coordinates</span>
                <span class="o">*</span><span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start_y</span><span class="p">,</span> <span class="n">start_y</span> <span class="o">+</span> <span class="n">y</span><span class="p">),</span>  <span class="c1"># y coordinates</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">start_x</span><span class="p">,</span> <span class="n">start_x</span> <span class="o">+</span> <span class="n">x</span><span class="p">),</span>  <span class="c1"># x coordinates</span>
                    <span class="n">indexing</span><span class="o">=</span><span class="s1">&#39;ij&#39;</span><span class="p">,</span>
                <span class="p">),</span>
            <span class="p">],</span>
            <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
        <span class="p">)</span>  <span class="c1"># coordinates of the 2d output pixels in the coordinate system of the input volume, so shape (y,x,3)</span>
        <span class="k">if</span> <span class="n">offset</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pixel_coord_y_x_zyx</span> <span class="o">=</span> <span class="n">pixel_coord_y_x_zyx</span> <span class="o">+</span> <span class="n">offset</span>
        <span class="k">if</span> <span class="n">rotation_center</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># default rotation center is the center of the volume, i.e. for 4 pixels</span>
            <span class="c1"># 0 1 2 3 it is between 0 and 1</span>
            <span class="n">rotation_center</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">input_shape</span><span class="o">.</span><span class="n">z</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">y</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">x</span> <span class="o">/</span> <span class="mi">2</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">])</span>
        <span class="n">pixel_rotated_y_x_zyx</span> <span class="o">=</span> <span class="n">rotation</span><span class="p">(</span><span class="n">pixel_coord_y_x_zyx</span> <span class="o">-</span> <span class="n">rotation_center</span><span class="p">)</span> <span class="o">+</span> <span class="n">rotation_center</span>

        <span class="c1"># We cast a ray from the pixel normal to the plane in both directions</span>
        <span class="c1"># points in the original volume further away then w will not be considered</span>
        <span class="n">ray</span> <span class="o">=</span> <span class="n">rotation</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
                <span class="p">[</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="n">w</span><span class="p">,</span> <span class="n">w</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>  <span class="c1"># z</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">w</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>  <span class="c1"># y</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">w</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>  <span class="c1"># x</span>
                <span class="p">],</span>
                <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="p">)</span>
        <span class="c1"># In all possible directions for each point along the line we consider the eight neighboring points</span>
        <span class="c1"># by adding all possible combinations of 0 and 1 to the point and flooring</span>
        <span class="n">offsets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">product</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">repeat</span><span class="o">=</span><span class="mi">3</span><span class="p">)))</span>
        <span class="c1"># all points that influence a pixel</span>
        <span class="c1"># x,y,8-neighbors,(2*w+1)-raylength,3-dimensions input_shape.xinput_shape.yinput_shape.z)</span>
        <span class="n">points_influencing_pixel</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">pixel_rotated_y_x_zyx</span><span class="p">,</span> <span class="s1">&#39;   y x zyxdim -&gt; y x 1          1   zyxdim&#39;</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">ray</span><span class="p">,</span> <span class="s1">&#39;                   ray zyxdim -&gt; 1 1 1          ray zyxdim&#39;</span><span class="p">)</span>
            <span class="o">+</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span><span class="n">offsets</span><span class="p">,</span> <span class="s1">&#39;        neighbors zyxdim -&gt; 1 1 neighbors 1   zyxdim&#39;</span><span class="p">)</span>
        <span class="p">)</span><span class="o">.</span><span class="n">floor</span><span class="p">()</span>  <span class="c1"># y x neighbors ray zyx</span>
        <span class="c1"># directional distance in source volume coordinate system</span>
        <span class="n">distance</span> <span class="o">=</span> <span class="n">pixel_rotated_y_x_zyx</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="n">points_influencing_pixel</span>
        <span class="c1"># Inverse rotation projects this back to the original coordinate system, i.e</span>
        <span class="c1"># Distance in z is distance along the line, i.e. the slice profile weighted direction</span>
        <span class="c1"># Distance in x and y is the distance of a pixel to the ray and linear interpolation</span>
        <span class="c1"># is used to weight the distance</span>
        <span class="n">distance_z</span><span class="p">,</span> <span class="n">distance_y</span><span class="p">,</span> <span class="n">distance_x</span> <span class="o">=</span> <span class="n">rotation</span><span class="p">(</span><span class="n">distance</span><span class="p">,</span> <span class="n">inverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">weight_yx</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">distance_y</span><span class="o">.</span><span class="n">abs</span><span class="p">())</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">distance_x</span><span class="o">.</span><span class="n">abs</span><span class="p">())</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">weight_z</span> <span class="o">=</span> <span class="n">slice_function</span><span class="p">(</span><span class="n">distance_z</span><span class="p">)</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="p">(</span><span class="n">weight_yx</span> <span class="o">*</span> <span class="n">weight_z</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">source</span> <span class="o">=</span> <span class="n">einops</span><span class="o">.</span><span class="n">rearrange</span><span class="p">(</span>
            <span class="n">points_influencing_pixel</span><span class="p">,</span>
            <span class="s1">&#39;y x neighbors raylength zyxdim -&gt; (y x) (neighbors raylength) zyxdim&#39;</span><span class="p">,</span>
        <span class="p">)</span><span class="o">.</span><span class="n">int</span><span class="p">()</span>

        <span class="c1"># mask of only potential source points inside the source volume</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span>
            <span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">z</span><span class="p">)</span>
            <span class="o">&amp;</span> <span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
            <span class="o">&amp;</span> <span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
            <span class="o">&amp;</span> <span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
            <span class="o">&amp;</span> <span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">x</span><span class="p">)</span>
            <span class="o">&amp;</span> <span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1"># We need this at the edge of the volume to approximate zero padding</span>
        <span class="n">fraction_in_view</span> <span class="o">=</span> <span class="p">(</span><span class="n">mask</span> <span class="o">*</span> <span class="p">(</span><span class="n">weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">weight</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">source_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">ravel_multi_index</span><span class="p">(</span><span class="n">source</span><span class="p">[</span><span class="n">mask</span><span class="p">]</span><span class="o">.</span><span class="n">unbind</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="n">input_shape</span><span class="o">.</span><span class="n">z</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">x</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="n">target_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="n">x</span><span class="p">),</span> <span class="n">mask</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
            <span class="c1"># beta status in pytorch causes a warning to be printed</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s1">&#39;Sparse&#39;</span><span class="p">)</span>

            <span class="n">matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo_tensor</span><span class="p">(</span>
                <span class="n">indices</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">target_index</span><span class="p">,</span> <span class="n">source_index</span><span class="p">)),</span>
                <span class="n">values</span><span class="o">=</span><span class="n">weight</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)[</span><span class="n">mask</span><span class="p">],</span>
                <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">z</span> <span class="o">*</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">x</span><span class="p">),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
            <span class="p">)</span><span class="o">.</span><span class="n">coalesce</span><span class="p">()</span>

            <span class="c1"># To avoid giving more weight to points that are duplicated in our ray</span>
            <span class="c1"># logic and got summed in the coalesce operation, we normalize by the number</span>
            <span class="c1"># of duplicates. This is equivalent to the sum of the weights of the duplicates.</span>
            <span class="c1"># Count duplicates...</span>

            <span class="n">ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">source_index</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sparse_coo_tensor</span><span class="p">(</span>
                <span class="n">indices</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">((</span><span class="n">target_index</span><span class="p">,</span> <span class="n">source_index</span><span class="p">)),</span>
                <span class="n">values</span><span class="o">=</span><span class="n">ones</span><span class="p">,</span>
                <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">z</span> <span class="o">*</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">input_shape</span><span class="o">.</span><span class="n">x</span><span class="p">),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="c1"># Coalesce sums the values of duplicate indices</span>
            <span class="n">ones</span> <span class="o">=</span> <span class="n">ones</span><span class="o">.</span><span class="n">coalesce</span><span class="p">()</span>

        <span class="c1"># .. and normalize by the number of duplicates</span>
        <span class="n">matrix</span><span class="o">.</span><span class="n">values</span><span class="p">()[:]</span> <span class="o">/=</span> <span class="n">ones</span><span class="o">.</span><span class="n">values</span><span class="p">()</span>

        <span class="c1"># Normalize for slice profile, so that the sum of the weights is 1</span>
        <span class="c1"># independent of the number of points that are considered.</span>
        <span class="c1"># Within the volume, the column sum should be 1,</span>
        <span class="c1"># at the edge of the volume, the column sum should be the fraction of the slice</span>
        <span class="c1"># that is in view to approximate zero padding</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="n">fraction_in_view</span> <span class="o">/</span> <span class="p">(</span><span class="n">matrix</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">to_dense</span><span class="p">()</span> <span class="o">+</span> <span class="mf">1e-6</span><span class="p">)</span>
        <span class="n">matrix</span> <span class="o">*=</span> <span class="n">norm</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">matrix</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Physikalisch-Technische Bundesanstalt (PTB) Berlin.</p>
  </div>

   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>